{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import stats\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "# # Set visualization style\n",
    "# plt.style.use('seaborn')\n",
    "# sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features for bengaluru train set\n",
      "Creating lag features for bengaluru val set\n",
      "Creating lag features for bengaluru test set\n",
      "\n",
      "Bengaluru data loaded:\n",
      "Train: 1241 samples\n",
      "Validation: 287 samples\n",
      "Test: 382 samples\n",
      "Creating lag features for chennai train set\n",
      "Creating lag features for chennai val set\n",
      "Creating lag features for chennai test set\n",
      "\n",
      "Chennai data loaded:\n",
      "Train: 1224 samples\n",
      "Validation: 283 samples\n",
      "Test: 377 samples\n",
      "Creating lag features for delhi train set\n",
      "Creating lag features for delhi val set\n",
      "Creating lag features for delhi test set\n",
      "\n",
      "Delhi data loaded:\n",
      "Train: 1299 samples\n",
      "Validation: 300 samples\n",
      "Test: 400 samples\n",
      "Creating lag features for hyderabad train set\n",
      "Creating lag features for hyderabad val set\n",
      "Creating lag features for hyderabad test set\n",
      "\n",
      "Hyderabad data loaded:\n",
      "Train: 1222 samples\n",
      "Validation: 282 samples\n",
      "Test: 376 samples\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(data, target_col='AQI', n_lags=7):\n",
    "    \"\"\"Create lag features for the target column\"\"\"\n",
    "    data = data.sort_values('Date')\n",
    "    for i in range(1, n_lags + 1):\n",
    "        data[f'{target_col}_lag_{i}'] = data[target_col].shift(i)\n",
    "    return data\n",
    "\n",
    "# Cell 2: Load pre-split data for each city\n",
    "processed_dir = '../data/processed'\n",
    "cities = ['bengaluru', 'chennai', 'delhi', 'hyderabad']\n",
    "\n",
    "# Dictionary to store data for each city\n",
    "city_data = {}\n",
    "\n",
    "for city in cities:\n",
    "    city_dir = f'{processed_dir}/{city.lower()}'\n",
    "    city_data[city] = {\n",
    "        'train': pd.read_csv(f'{city_dir}/train.csv'),\n",
    "        'val': pd.read_csv(f'{city_dir}/val.csv'),\n",
    "        'test': pd.read_csv(f'{city_dir}/test.csv')\n",
    "    }\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        city_data[city][split]['Date'] = pd.to_datetime(city_data[city][split]['Date'])\n",
    "        \n",
    "        # Check if lag features exist, if not create them\n",
    "        if 'AQI_lag_1' not in city_data[city][split].columns:\n",
    "            print(f\"Creating lag features for {city} {split} set\")\n",
    "            city_data[city][split] = create_lag_features(city_data[city][split])\n",
    "    \n",
    "    print(f\"\\n{city.title()} data loaded:\")\n",
    "    print(f\"Train: {city_data[city]['train'].shape[0]} samples\")\n",
    "    print(f\"Validation: {city_data[city]['val'].shape[0]} samples\")\n",
    "    print(f\"Test: {city_data[city]['test'].shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define utility functions\n",
    "def calculate_metrics(y_true, y_pred, prefix=''):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics with confidence intervals\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Remove any NaN values from both arrays\n",
    "    mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        print(\"Warning: No valid data points after removing NaN values\")\n",
    "        return {f'{prefix}rmse': np.nan, f'{prefix}mae': np.nan, f'{prefix}r2': np.nan}\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    metrics[f'{prefix}rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    metrics[f'{prefix}mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics[f'{prefix}r2'] = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate confidence intervals using bootstrap\n",
    "    n_iterations = 1000\n",
    "    n_samples = len(y_true)\n",
    "    \n",
    "    # Initialize arrays to store bootstrap metrics\n",
    "    rmse_boots = np.zeros(n_iterations)\n",
    "    mae_boots = np.zeros(n_iterations)\n",
    "    r2_boots = np.zeros(n_iterations)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Sample with replacement\n",
    "        indices = np.random.randint(0, n_samples, n_samples)\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_pred_boot = y_pred[indices]\n",
    "        \n",
    "        # Calculate metrics for this bootstrap sample\n",
    "        rmse_boots[i] = np.sqrt(mean_squared_error(y_true_boot, y_pred_boot))\n",
    "        mae_boots[i] = mean_absolute_error(y_true_boot, y_pred_boot)\n",
    "        r2_boots[i] = r2_score(y_true_boot, y_pred_boot)\n",
    "    \n",
    "    # Calculate 95% confidence intervals\n",
    "    for metric_name, metric_boots in [('rmse', rmse_boots), ('mae', mae_boots), ('r2', r2_boots)]:\n",
    "        lower, upper = np.percentile(metric_boots, [2.5, 97.5])\n",
    "        metrics[f'{prefix}{metric_name}_ci'] = (lower, upper)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print metrics in a formatted way\"\"\"\n",
    "    if isinstance(metrics, tuple):\n",
    "        # Handle confidence intervals\n",
    "        print(f\"({metrics[0]:.3f}, {metrics[1]:.3f})\")\n",
    "    elif isinstance(metrics, dict):\n",
    "        # Handle metric dictionaries\n",
    "        for metric_name, value in metrics.items():\n",
    "            if isinstance(value, tuple):\n",
    "                print(f\"{metric_name}: ({value[0]:.3f}, {value[1]:.3f})\")\n",
    "            else:\n",
    "                print(f\"{metric_name}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"Unknown metric type: {type(metrics)}\")\n",
    "\n",
    "def plot_metrics_comparison(city, results):\n",
    "    \"\"\"Plot comparison of metrics for different models\"\"\"\n",
    "    models = ['persistence', 'moving_average']\n",
    "    metrics = ['rmse', 'mae', 'r2']\n",
    "    splits = ['validation', 'test']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        # Get values and confidence intervals for each split\n",
    "        values = {split: [] for split in splits}\n",
    "        cis = {split: [] for split in splits}\n",
    "        \n",
    "        for model in models:\n",
    "            for split in splits:\n",
    "                metric_key = f'{split[:3]}_{metric}'\n",
    "                ci_key = f'{split[:3]}_{metric}_ci'\n",
    "                \n",
    "                if split in results[model] and metric_key in results[model][split]:\n",
    "                    values[split].append(results[model][split][metric_key])\n",
    "                    cis[split].append(results[model][split][ci_key])\n",
    "        \n",
    "        # Only plot if we have data\n",
    "        if any(values[split] for split in splits):\n",
    "            # Plot bars with error bars for each split\n",
    "            x = np.arange(len(models))\n",
    "            width = 0.35\n",
    "            \n",
    "            for i, split in enumerate(splits):\n",
    "                if values[split]:  # Only plot if we have values\n",
    "                    axes[idx].bar(x + i*width, values[split], width,\n",
    "                                yerr=[(v-ci[0], ci[1]-v) for v, ci in zip(values[split], cis[split])],\n",
    "                                label=split.title(), capsize=5, alpha=0.7)\n",
    "            \n",
    "            axes[idx].set_xticks(x + width/2)\n",
    "            axes[idx].set_xticklabels([m.replace('_', ' ').title() for m in models])\n",
    "            axes[idx].set_title(f'{metric.upper()} Comparison')\n",
    "            axes[idx].set_ylabel(metric.upper())\n",
    "            axes[idx].legend()\n",
    "        else:\n",
    "            # If no data, show a message\n",
    "            axes[idx].text(0.5, 0.5, 'No data available',\n",
    "                         horizontalalignment='center',\n",
    "                         verticalalignment='center',\n",
    "                         transform=axes[idx].transAxes)\n",
    "            axes[idx].set_title(f'{metric.upper()} Comparison')\n",
    "    \n",
    "    plt.suptitle(f'Model Performance Comparison - {city.title()}', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_predictions(city, results, data_split='test'):\n",
    "    \"\"\"Plot predictions from baseline models\"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Get actual values\n",
    "    actual = city_data[city][data_split]['AQI']\n",
    "    dates = city_data[city][data_split]['Date']\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(dates, actual, label='Actual', color='black', alpha=0.6)\n",
    "    \n",
    "    # Plot predictions for each model\n",
    "    for model_name, color in [('persistence', 'blue'), ('moving_average', 'red')]:\n",
    "        predictions = results[model_name]['predictions'][data_split]\n",
    "        plt.plot(dates, predictions, \n",
    "                label=model_name.replace('_', ' ').title(),\n",
    "                color=color, alpha=0.6)\n",
    "    \n",
    "    plt.title(f'{city.title()} - {data_split.title()} Set Predictions')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('AQI')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_feature_importance(city, results):\n",
    "    \"\"\"Plot feature importance for models that support it\"\"\"\n",
    "    # Get models with feature importance\n",
    "    models_with_importance = {\n",
    "        name: results[name]['model_config']['feature_importance']\n",
    "        for name in results\n",
    "        if results[name]['model_config']['feature_importance'] is not None\n",
    "    }\n",
    "    \n",
    "    if not models_with_importance:\n",
    "        print(\"No models with feature importance found\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    n_models = len(models_with_importance)\n",
    "    fig, axes = plt.subplots(n_models, 1, figsize=(15, 5*n_models))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (model_name, importance) in enumerate(models_with_importance.items()):\n",
    "        # Sort features by importance\n",
    "        sorted_features = sorted(importance.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "        features, values = zip(*sorted_features)\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = axes[idx].barh(features, values)\n",
    "        \n",
    "        # Color bars based on sign\n",
    "        for bar in bars:\n",
    "            if bar.get_width() < 0:\n",
    "                bar.set_color('red')\n",
    "            else:\n",
    "                bar.set_color('blue')\n",
    "        \n",
    "        # Add vertical line at x=0\n",
    "        axes[idx].axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        axes[idx].set_title(f'Feature Importance - {model_name.replace(\"_\", \" \").title()}')\n",
    "        axes[idx].set_xlabel('Importance')\n",
    "        axes[idx].set_ylabel('Features')\n",
    "    \n",
    "    plt.suptitle(f'Feature Importance Analysis - {city.title()}', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Define baseline models\n",
    "class PersistenceModel:\n",
    "    def __init__(self):\n",
    "        self.name = \"Persistence\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # No training needed for persistence model\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # For persistence model, we'll use the 1-day lag if it exists\n",
    "        if 'AQI_lag_1' not in X.columns:\n",
    "            raise ValueError(\"AQI_lag_1 feature not found in the data\")\n",
    "        return X['AQI_lag_1'].values\n",
    "\n",
    "class MovingAverageModel:\n",
    "    def __init__(self, window_size=7):\n",
    "        self.name = \"Moving Average\"\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # No training needed for moving average model\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Create a rolling window of lag features\n",
    "        lag_cols = [f'AQI_lag_{i}' for i in range(1, self.window_size + 1)]\n",
    "        if not all(col in X.columns for col in lag_cols):\n",
    "            raise ValueError(f\"Required lag features not found in the data\")\n",
    "        \n",
    "        # Calculate moving average\n",
    "        lag_values = X[lag_cols].values\n",
    "        return np.nanmean(lag_values, axis=1)  # Use nanmean to handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Function to evaluate baseline models\n",
    "def evaluate_baseline_models(city_data, city_name):\n",
    "    \"\"\"Evaluate baseline models for a specific city\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Initialize models\n",
    "    persistence = PersistenceModel()\n",
    "    moving_avg = MovingAverageModel(window_size=7)\n",
    "    \n",
    "    # Fit and evaluate persistence model\n",
    "    persistence.fit(city_data['train'], city_data['train']['AQI'])\n",
    "    val_pred_persistence = persistence.predict(city_data['val'])\n",
    "    test_pred_persistence = persistence.predict(city_data['test'])\n",
    "\n",
    "    # Calculate feature importance for persistence model\n",
    "    # For persistence, the importance is 1 for lag_1 and 0 for others\n",
    "    persistence_importance = {\n",
    "        'AQI_lag_1': 1.0,\n",
    "        'AQI_lag_2': 0.0,\n",
    "        'AQI_lag_3': 0.0,\n",
    "        'AQI_lag_4': 0.0,\n",
    "        'AQI_lag_5': 0.0,\n",
    "        'AQI_lag_6': 0.0,\n",
    "        'AQI_lag_7': 0.0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Fit and evaluate moving average model\n",
    "    moving_avg.fit(city_data['train'], city_data['train']['AQI'])\n",
    "    val_pred_ma = moving_avg.predict(city_data['val'])\n",
    "    test_pred_ma = moving_avg.predict(city_data['test'])\n",
    "\n",
    "     # Calculate feature importance for moving average\n",
    "    # For moving average, each lag has equal importance (1/window_size)\n",
    "    ma_importance = {\n",
    "        f'AQI_lag_{i}': 1.0/moving_avg.window_size \n",
    "        for i in range(1, moving_avg.window_size + 1)\n",
    "    }\n",
    "    # Add zeros for lags beyond window size\n",
    "    for i in range(moving_avg.window_size + 1, 8):\n",
    "        ma_importance[f'AQI_lag_{i}'] = 0.0\n",
    "    \n",
    "    \n",
    "    # Calculate metrics\n",
    "    persistence_val_metrics = calculate_metrics(city_data['val']['AQI'].values, val_pred_persistence, 'val_')\n",
    "    persistence_test_metrics = calculate_metrics(city_data['test']['AQI'].values, test_pred_persistence, 'test_')\n",
    "    \n",
    "    ma_val_metrics = calculate_metrics(city_data['val']['AQI'].values, val_pred_ma, 'val_')\n",
    "    ma_test_metrics = calculate_metrics(city_data['test']['AQI'].values, test_pred_ma, 'test_')\n",
    "\n",
    "    \n",
    "    # Store results\n",
    "    results['persistence'] = {\n",
    "        'validation': persistence_val_metrics,\n",
    "        'test': persistence_test_metrics,\n",
    "        'predictions': {\n",
    "            'val': val_pred_persistence,\n",
    "            'test': test_pred_persistence\n",
    "        },\n",
    "        'model_config': {\n",
    "            'name': 'Persistence',\n",
    "            'parameters': {},\n",
    "            'feature_importance': persistence_importance\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results['moving_average'] = {\n",
    "        'validation': ma_val_metrics,\n",
    "        'test': ma_test_metrics,\n",
    "        'predictions': {\n",
    "            'val': val_pred_ma,\n",
    "            'test': test_pred_ma\n",
    "        },\n",
    "        'model_config': {\n",
    "            'name': 'Moving Average',\n",
    "            'parameters': {'window_size': moving_avg.window_size},\n",
    "            'feature_importance': ma_importance\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Update the ModelResultsManager class to handle ML results\n",
    "class ModelResultsManager:\n",
    "    def __init__(self):\n",
    "        self.base_dir = \"./results\"\n",
    "        self.ml_dir = f\"{self.base_dir}/ml_models\"\n",
    "        self._create_directory_structure()\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        os.makedirs(self.ml_dir, exist_ok=True)\n",
    "        for city in ['Bengaluru', 'Chennai', 'Delhi', 'Hyderabad']:\n",
    "            city_dir = f\"{self.ml_dir}/{city}\"\n",
    "            os.makedirs(city_dir, exist_ok=True)\n",
    "            os.makedirs(f\"{city_dir}/visualizations\", exist_ok=True)\n",
    "    \n",
    "    def save_ml_results(self, city, results):\n",
    "        \"\"\"Save ML model results\"\"\"\n",
    "        city_dir = f\"{self.ml_dir}/{city}\"\n",
    "        \n",
    "        # Save results for each model\n",
    "        for model_name, model_results in results.items():\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            serializable_results = {\n",
    "                'validation': model_results['validation'],\n",
    "                'test': model_results['test'],\n",
    "                'predictions': model_results['predictions'],\n",
    "                'model_config': model_results['model_config']\n",
    "            }\n",
    "            \n",
    "            # Save to file\n",
    "            with open(f\"{city_dir}/{model_name}_results.json\", 'w') as f:\n",
    "                json.dump(serializable_results, f, indent=4)\n",
    "        \n",
    "        # Update metadata\n",
    "        self._update_metadata(city, results)\n",
    "    \n",
    "    def _update_metadata(self, city, results):\n",
    "        \"\"\"Update metadata file with ML model results\"\"\"\n",
    "        metadata_file = f\"{self.base_dir}/metadata.json\"\n",
    "        \n",
    "        # Load existing metadata\n",
    "        if os.path.exists(metadata_file):\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Update ML results\n",
    "        if 'ml_models' not in metadata:\n",
    "            metadata['ml_models'] = {}\n",
    "        \n",
    "        metadata['ml_models'][city] = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'models': list(results.keys()),\n",
    "            'metrics': {\n",
    "                model: {\n",
    "                    'validation': {\n",
    "                        'rmse': results[model]['validation'][f'val_rmse'],\n",
    "                        'mae': results[model]['validation'][f'val_mae'],\n",
    "                        'r2': results[model]['validation'][f'val_r2']\n",
    "                    },\n",
    "                    'test': {\n",
    "                        'rmse': results[model]['test'][f'test_rmse'],\n",
    "                        'mae': results[model]['test'][f'test_mae'],\n",
    "                        'r2': results[model]['test'][f'test_r2']\n",
    "                    }\n",
    "                }\n",
    "                for model in results\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define ModelResultsManager class\n",
    "class ModelResultsManager:\n",
    "    def __init__(self, base_dir='results'):\n",
    "        self.base_dir = base_dir\n",
    "        self._create_directory_structure()\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Create necessary directories for storing results\"\"\"\n",
    "        os.makedirs(f'{self.base_dir}', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/model_configs', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/predictions', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/performance_metrics', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/plots', exist_ok=True)\n",
    "    \n",
    "    def _convert_to_serializable(self, obj):\n",
    "        \"\"\"Convert numpy arrays and other non-serializable objects to serializable format\"\"\"\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: self._convert_to_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self._convert_to_serializable(item) for item in obj]\n",
    "        elif isinstance(obj, tuple):\n",
    "            return tuple(self._convert_to_serializable(item) for item in obj)\n",
    "        elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8,\n",
    "                            np.uint64, np.uint32, np.uint16, np.uint8)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float64, np.float32, np.float16)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        return obj\n",
    "    \n",
    "    def _update_metadata(self, city_name, model_type, results):\n",
    "        \"\"\"Update metadata file with latest results\"\"\"\n",
    "        metadata_file = f'{self.base_dir}/metadata.json'\n",
    "        \n",
    "        # Load existing metadata or create new\n",
    "        if os.path.exists(metadata_file):\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Update metadata for this city and model type\n",
    "        if city_name not in metadata:\n",
    "            metadata[city_name] = {}\n",
    "        \n",
    "        metadata[city_name][model_type] = {\n",
    "            'last_updated': datetime.now().isoformat(),\n",
    "            'metrics_used': ['rmse', 'mae', 'r2'],\n",
    "            'results': {\n",
    "                'persistence': {\n",
    "                    'validation': results['persistence']['validation'],\n",
    "                    'test': results['persistence']['test']\n",
    "                },\n",
    "                'moving_average': {\n",
    "                    'validation': results['moving_average']['validation'],\n",
    "                    'test': results['moving_average']['test']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    def save_baseline_results(self, city_name, results):\n",
    "        \"\"\"Save baseline model results for a city\"\"\"\n",
    "        # Convert results to serializable format\n",
    "        serializable_results = self._convert_to_serializable(results)\n",
    "        \n",
    "        # Save performance metrics\n",
    "        metrics_file = f'{self.base_dir}/performance_metrics/baseline_{city_name}.json'\n",
    "        with open(metrics_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=4)\n",
    "        \n",
    "        # Save predictions\n",
    "        pred_dir = f'{self.base_dir}/predictions/{city_name}'\n",
    "        os.makedirs(pred_dir, exist_ok=True)\n",
    "        \n",
    "        for model_name in ['persistence', 'moving_average']:\n",
    "            pred_data = {\n",
    "                'validation': serializable_results[model_name]['predictions']['val'],\n",
    "                'test': serializable_results[model_name]['predictions']['test']\n",
    "            }\n",
    "            with open(f'{pred_dir}/{model_name}_predictions.json', 'w') as f:\n",
    "                json.dump(pred_data, f, indent=4)\n",
    "        \n",
    "        # Update metadata\n",
    "        self._update_metadata(city_name, 'baseline', serializable_results)\n",
    "    \n",
    "    def save_plots(self, city_name, fig, plot_name):\n",
    "        \"\"\"Save plots for a city\"\"\"\n",
    "        # Create directory for city plots if it doesn't exist\n",
    "        plot_dir = f'{self.base_dir}/plots/{city_name}'\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_path = f'{plot_dir}/{plot_name}.png'\n",
    "        fig.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    def load_baseline_results(self, city_name):\n",
    "        \"\"\"Load baseline model results for a city\"\"\"\n",
    "        metrics_file = f'{self.base_dir}/performance_metrics/baseline_{city_name}.json'\n",
    "        if not os.path.exists(metrics_file):\n",
    "            raise FileNotFoundError(f\"No results found for {city_name}\")\n",
    "        \n",
    "        with open(metrics_file, 'r') as f:\n",
    "            return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline models for bengaluru\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 17.738\n",
      "val_mae: 12.563\n",
      "val_r2: 0.512\n",
      "val_rmse_ci: (15.447, 19.924)\n",
      "val_mae_ci: (11.164, 13.959)\n",
      "val_r2_ci: (0.374, 0.626)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 11.324\n",
      "test_mae: 7.906\n",
      "test_r2: 0.667\n",
      "test_rmse_ci: (9.908, 12.743)\n",
      "test_mae_ci: (7.089, 8.725)\n",
      "test_r2_ci: (0.568, 0.748)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 21.624\n",
      "val_mae: 16.289\n",
      "val_r2: 0.275\n",
      "val_rmse_ci: (19.191, 24.009)\n",
      "val_mae_ci: (14.593, 17.997)\n",
      "val_r2_ci: (0.133, 0.396)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 13.973\n",
      "test_mae: 9.713\n",
      "test_r2: 0.492\n",
      "test_rmse_ci: (12.153, 15.969)\n",
      "test_mae_ci: (8.788, 10.747)\n",
      "test_r2_ci: (0.393, 0.576)\n",
      "\n",
      "Results and plots saved for bengaluru\n",
      "\n",
      "Evaluating baseline models for chennai\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 36.885\n",
      "val_mae: 23.734\n",
      "val_r2: 0.269\n",
      "val_rmse_ci: (31.829, 42.538)\n",
      "val_mae_ci: (20.573, 27.167)\n",
      "val_r2_ci: (0.038, 0.445)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 27.243\n",
      "test_mae: 16.415\n",
      "test_r2: 0.426\n",
      "test_rmse_ci: (22.351, 31.829)\n",
      "test_mae_ci: (14.231, 18.527)\n",
      "test_r2_ci: (0.188, 0.594)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 43.660\n",
      "val_mae: 31.500\n",
      "val_r2: -0.025\n",
      "val_rmse_ci: (37.913, 49.432)\n",
      "val_mae_ci: (27.780, 35.381)\n",
      "val_r2_ci: (-0.177, 0.121)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 32.677\n",
      "test_mae: 19.959\n",
      "test_r2: 0.174\n",
      "test_rmse_ci: (27.032, 38.371)\n",
      "test_mae_ci: (17.619, 22.741)\n",
      "test_r2_ci: (-0.113, 0.367)\n",
      "\n",
      "Results and plots saved for chennai\n",
      "\n",
      "Evaluating baseline models for delhi\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 53.260\n",
      "val_mae: 39.077\n",
      "val_r2: 0.792\n",
      "val_rmse_ci: (47.063, 59.338)\n",
      "val_mae_ci: (34.879, 43.254)\n",
      "val_r2_ci: (0.731, 0.838)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 45.105\n",
      "test_mae: 31.559\n",
      "test_r2: 0.843\n",
      "test_rmse_ci: (40.717, 49.808)\n",
      "test_mae_ci: (28.661, 35.069)\n",
      "test_r2_ci: (0.806, 0.872)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 65.436\n",
      "val_mae: 50.511\n",
      "val_r2: 0.686\n",
      "val_rmse_ci: (59.141, 71.402)\n",
      "val_mae_ci: (45.685, 55.404)\n",
      "val_r2_ci: (0.611, 0.746)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 66.572\n",
      "test_mae: 46.647\n",
      "test_r2: 0.658\n",
      "test_rmse_ci: (60.559, 72.841)\n",
      "test_mae_ci: (42.198, 51.500)\n",
      "test_r2_ci: (0.574, 0.714)\n",
      "\n",
      "Results and plots saved for delhi\n",
      "\n",
      "Evaluating baseline models for hyderabad\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 14.052\n",
      "val_mae: 10.559\n",
      "val_r2: 0.719\n",
      "val_rmse_ci: (12.313, 15.932)\n",
      "val_mae_ci: (9.466, 11.555)\n",
      "val_r2_ci: (0.632, 0.794)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 14.221\n",
      "test_mae: 9.861\n",
      "test_r2: 0.840\n",
      "test_rmse_ci: (12.427, 15.973)\n",
      "test_mae_ci: (8.805, 10.939)\n",
      "test_r2_ci: (0.791, 0.878)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 21.699\n",
      "val_mae: 16.349\n",
      "val_r2: 0.331\n",
      "val_rmse_ci: (19.653, 23.974)\n",
      "val_mae_ci: (14.894, 18.068)\n",
      "val_r2_ci: (0.179, 0.454)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 21.981\n",
      "test_mae: 16.111\n",
      "test_r2: 0.619\n",
      "test_rmse_ci: (19.800, 24.086)\n",
      "test_mae_ci: (14.508, 17.673)\n",
      "test_r2_ci: (0.537, 0.683)\n",
      "\n",
      "Results and plots saved for hyderabad\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Run evaluation and save results\n",
    "results_manager = ModelResultsManager(\"./results/baseline\")\n",
    "baseline_results = {}\n",
    "\n",
    "for city in cities:\n",
    "    print(f\"\\nEvaluating baseline models for {city}\")\n",
    "    baseline_results[city] = evaluate_baseline_models(city_data[city], city)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nPersistence Model:\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print_metrics(baseline_results[city]['persistence']['validation'])\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print_metrics(baseline_results[city]['persistence']['test'])\n",
    "    \n",
    "    print(\"\\nMoving Average Model:\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print_metrics(baseline_results[city]['moving_average']['validation'])\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print_metrics(baseline_results[city]['moving_average']['test'])\n",
    "    \n",
    "    # Save results\n",
    "    results_manager.save_baseline_results(city, baseline_results[city])\n",
    "    \n",
    "    # Generate and save plots\n",
    "    fig = plot_metrics_comparison(city, baseline_results[city])\n",
    "    results_manager.save_plots(city, fig, 'metrics_comparison')\n",
    "    \n",
    "    fig = plot_predictions(city, baseline_results[city], 'test')\n",
    "    results_manager.save_plots(city, fig, 'test_predictions')\n",
    "\n",
    "    fig = plot_feature_importance(city, baseline_results[city])\n",
    "    results_manager.save_plots(city, fig, 'feature_importances')\n",
    "    \n",
    "    print(f\"\\nResults and plots saved for {city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelEvaluator:\n",
    "    def __init__(self, city_data, city_name):\n",
    "        self.city_data = city_data\n",
    "        self.city_name = city_name\n",
    "        self.scaler = StandardScaler()\n",
    "        self.results = {}\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare data for ML models\"\"\"\n",
    "        # Get numeric columns only (excluding date, city, and AQI)\n",
    "        numeric_cols = self.city_data['train'].select_dtypes(include=[np.number]).columns\n",
    "        numeric_cols = [col for col in numeric_cols if col not in ['AQI']]\n",
    "        \n",
    "        # Separate features and target\n",
    "        X_train = self.city_data['train'][numeric_cols]\n",
    "        y_train = self.city_data['train']['AQI']\n",
    "        \n",
    "        X_val = self.city_data['val'][numeric_cols]\n",
    "        y_val = self.city_data['val']['AQI']\n",
    "        \n",
    "        X_test = self.city_data['test'][numeric_cols]\n",
    "        y_test = self.city_data['test']['AQI']\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.scaler.transform(X_val)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        return {\n",
    "            'train': {'X': X_train_scaled, 'y': y_train},\n",
    "            'val': {'X': X_val_scaled, 'y': y_val},\n",
    "            'test': {'X': X_test_scaled, 'y': y_test},\n",
    "            'feature_names': numeric_cols  # Removed .tolist() since it's already a list\n",
    "        }\n",
    "    \n",
    "    def calculate_confidence_intervals(self, y_true, y_pred, metric_func, n_bootstrap=1000):\n",
    "        \"\"\"Calculate 95% confidence intervals using bootstrap sampling\"\"\"\n",
    "        scores = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "            score = metric_func(y_true[indices], y_pred[indices])\n",
    "            scores.append(score)\n",
    "        return np.percentile(scores, [2.5, 97.5])\n",
    "    \n",
    "    def evaluate_model(self, model, model_name, param_grid=None):\n",
    "        \"\"\"Evaluate a single ML model\"\"\"\n",
    "        data = self.prepare_data()\n",
    "        \n",
    "        if param_grid:\n",
    "            grid_search = GridSearchCV(\n",
    "                model, param_grid, cv=5, scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1, verbose=1\n",
    "            )\n",
    "            grid_search.fit(data['train']['X'], data['train']['y'])\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "        else:\n",
    "            best_model = model\n",
    "            best_model.fit(data['train']['X'], data['train']['y'])\n",
    "            best_params = {}\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = {\n",
    "            'val': best_model.predict(data['val']['X']),\n",
    "            'test': best_model.predict(data['test']['X'])\n",
    "        }\n",
    "        \n",
    "        # Calculate metrics with confidence intervals\n",
    "        metrics = {}\n",
    "        for split in ['val', 'test']:\n",
    "            y_true = data[split]['y']\n",
    "            y_pred = predictions[split]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            \n",
    "            # Calculate confidence intervals\n",
    "            rmse_ci = self.calculate_confidence_intervals(\n",
    "                y_true, y_pred, lambda yt, yp: np.sqrt(mean_squared_error(yt, yp))\n",
    "            )\n",
    "            mae_ci = self.calculate_confidence_intervals(\n",
    "                y_true, y_pred, mean_absolute_error\n",
    "            )\n",
    "            r2_ci = self.calculate_confidence_intervals(\n",
    "                y_true, y_pred, r2_score\n",
    "            )\n",
    "            \n",
    "            metrics[split] = {\n",
    "                f'{split}_rmse': rmse,\n",
    "                f'{split}_mae': mae,\n",
    "                f'{split}_r2': r2,\n",
    "                f'{split}_rmse_ci': rmse_ci.tolist(),\n",
    "                f'{split}_mae_ci': mae_ci.tolist(),\n",
    "                f'{split}_r2_ci': r2_ci.tolist()\n",
    "            }\n",
    "        \n",
    "        # Get feature importance if available\n",
    "        feature_importance = None\n",
    "        if hasattr(best_model, 'feature_importances_'):\n",
    "            feature_importance = dict(zip(data['feature_names'], \n",
    "                                       best_model.feature_importances_))\n",
    "        elif hasattr(best_model, 'coef_'):\n",
    "            feature_importance = dict(zip(data['feature_names'], \n",
    "                                       best_model.coef_))\n",
    "        elif isinstance(best_model, SVR) and best_model.kernel == 'rbf':\n",
    "            # For SVR with RBF kernel, use permutation importance\n",
    "            perm_importance = permutation_importance(\n",
    "                best_model, \n",
    "                data['test']['X'], \n",
    "                data['test']['y'],\n",
    "                n_repeats=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            feature_importance = dict(zip(data['feature_names'], perm_importance.importances_mean))\n",
    "        \n",
    "        # Store results in baseline-compatible format\n",
    "        self.results[model_name] = {\n",
    "            'val': metrics['val'],\n",
    "            'test': metrics['test'],\n",
    "            'predictions': {\n",
    "                'val': predictions['val'].tolist(),\n",
    "                'test': predictions['test'].tolist()\n",
    "            },\n",
    "            'model_config': {\n",
    "                'name': model_name,\n",
    "                'parameters': best_params,\n",
    "                'feature_importance': feature_importance\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return self.results[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_ml_models(city_data, city_name):\n",
    "    \"\"\"Evaluate all ML models for a given city\"\"\"\n",
    "    evaluator = MLModelEvaluator(city_data, city_name)\n",
    "    \n",
    "    # Define models and their parameter grids\n",
    "    models = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'param_grid': None\n",
    "        },\n",
    "        'ridge': {\n",
    "            'model': Ridge(),\n",
    "            'param_grid': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'param_grid': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            }\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': RandomForestRegressor(random_state=42),\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5]\n",
    "            }\n",
    "        },\n",
    "        'gradient_boosting': {\n",
    "            'model': GradientBoostingRegressor(random_state=42),\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 5]\n",
    "            }\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'model': xgb.XGBRegressor(random_state=42),\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 5]\n",
    "            }\n",
    "        },\n",
    "        'svr': {\n",
    "            'model': SVR(),\n",
    "            'param_grid': {\n",
    "                'kernel': ['linear', 'rbf'],\n",
    "                'C': [0.1, 1.0, 10.0],\n",
    "                'epsilon': [0.1, 0.2]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model_name, model_config in models.items():\n",
    "        print(f\"\\nEvaluating {model_name} for {city_name}...\")\n",
    "        evaluator.evaluate_model(\n",
    "            model_config['model'],\n",
    "            model_name,\n",
    "            model_config['param_grid']\n",
    "        )\n",
    "        \n",
    "    \n",
    "    return evaluator.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.int32, np.int64)):\n",
    "            return int(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "def save_ml_results(city_name, results):\n",
    "    \"\"\"Save ML model results\"\"\"\n",
    "    # Create results directory if it doesn't exist\n",
    "    results_dir = f\"./results/ml_models/{city_name}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results for each model\n",
    "    for model_name, model_results in results.items():\n",
    "        # Save to file using the custom encoder\n",
    "        with open(f\"{results_dir}/{model_name}_results.json\", 'w') as f:\n",
    "            json.dump(model_results, f, indent=4, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(city, results):\n",
    "    \"\"\"Plot comparison of metrics for different models\"\"\"\n",
    "    # Define metrics and splits\n",
    "    metrics = ['rmse', 'mae', 'r2']\n",
    "    splits = ['val', 'test']\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = list(results.keys())\n",
    "    n_models = len(models)\n",
    "    n_metrics = len(metrics)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, n_metrics, figsize=(6*n_metrics, 6))\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Collect values and confidence intervals\n",
    "        values = {split: [] for split in splits}\n",
    "        cis = {split: [] for split in splits}\n",
    "        \n",
    "        for model in models:\n",
    "            for split in splits:\n",
    "                metric_key = f'{split}_{metric}'\n",
    "                ci_key = f'{split}_{metric}_ci'\n",
    "                \n",
    "                if metric_key in results[model][split]:\n",
    "                    values[split].append(results[model][split][metric_key])\n",
    "                    # Convert CI to error bar format (half-width)\n",
    "                    ci = results[model][split][ci_key]\n",
    "                    if isinstance(ci, (list, np.ndarray)) and len(ci) == 2:\n",
    "                        ci_half_width = (ci[1] - ci[0]) / 2\n",
    "                        cis[split].append(ci_half_width)\n",
    "                    else:\n",
    "                        cis[split].append(0)  # No error bar if CI is invalid\n",
    "                else:\n",
    "                    values[split].append(None)\n",
    "                    cis[split].append(0)\n",
    "        \n",
    "        # Plot bars\n",
    "        x = np.arange(n_models)\n",
    "        width = 0.35\n",
    "        \n",
    "        for j, split in enumerate(splits):\n",
    "            valid_values = [v for v in values[split] if v is not None]\n",
    "            if valid_values:\n",
    "                ax.bar(x + j*width, values[split], width, label=split.capitalize())\n",
    "                \n",
    "                # Add error bars\n",
    "                for k, (val, ci) in enumerate(zip(values[split], cis[split])):\n",
    "                    if val is not None:\n",
    "                        ax.errorbar(x[k] + j*width, val, yerr=ci, \n",
    "                                  fmt='none', color='black', capsize=5)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Models')\n",
    "        ax.set_ylabel(metric.upper())\n",
    "        ax.set_title(f'{metric.upper()} Comparison')\n",
    "        ax.set_xticks(x + width/2)\n",
    "        ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_predictions(city, results, data_split, actual_values):\n",
    "    \"\"\"Plot actual vs predicted values for all models\"\"\"\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Plot actual values\n",
    "    ax.plot(actual_values, label='Actual', color='black', alpha=0.7)\n",
    "    \n",
    "    # Plot predictions for each model\n",
    "    for model_name, model_results in results.items():\n",
    "        predictions = model_results['predictions'][data_split]\n",
    "        ax.plot(predictions, label=model_name, alpha=0.7)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('AQI')\n",
    "    ax.set_title(f'Actual vs Predicted AQI - {data_split.capitalize()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_feature_importance(city, results):\n",
    "    \"\"\"Plot feature importance for models that support it\"\"\"\n",
    "    # Get models with feature importance\n",
    "    models_with_importance = {\n",
    "        name: results[name]['model_config']['feature_importance']\n",
    "        for name in results\n",
    "        if results[name]['model_config']['feature_importance'] is not None\n",
    "    }\n",
    "    \n",
    "    if not models_with_importance:\n",
    "        print(\"No models with feature importance found\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    n_models = len(models_with_importance)\n",
    "    fig, axes = plt.subplots(n_models, 1, figsize=(15, 5*n_models))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (model_name, importance) in enumerate(models_with_importance.items()):\n",
    "        print(f\"\\nDebugging {model_name}:\")\n",
    "        print(\"Feature importance structure:\", importance)\n",
    "        \n",
    "        # Handle different formats of feature importance\n",
    "        if isinstance(importance, dict):\n",
    "            # For models with dictionary format (most models)\n",
    "            sorted_features = sorted(importance.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "            features, values = zip(*sorted_features)\n",
    "            \n",
    "            # Convert values to float if they're arrays\n",
    "            try:\n",
    "                values = [float(v) if hasattr(v, '__len__') else v for v in values]\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting values: {e}\")\n",
    "                print(\"Original values:\", values)\n",
    "                # Try alternative conversion\n",
    "                values = [float(v[0]) if hasattr(v, '__len__') else float(v) for v in values]\n",
    "        else:\n",
    "            # For models with array format (SVR with linear kernel)\n",
    "            features = ['PM2.5']  # Assuming PM2.5 is the target\n",
    "            values = [float(importance[0])]  # Take the first value from the array\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = axes[idx].barh(features, values)\n",
    "        \n",
    "        # Color bars based on sign\n",
    "        for bar in bars:\n",
    "            if bar.get_width() < 0:\n",
    "                bar.set_color('red')\n",
    "            else:\n",
    "                bar.set_color('blue')\n",
    "        \n",
    "        # Add vertical line at x=0\n",
    "        axes[idx].axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        axes[idx].set_title(f'Feature Importance - {model_name.replace(\"_\", \" \").title()}')\n",
    "        axes[idx].set_xlabel('Importance')\n",
    "        axes[idx].set_ylabel('Features')\n",
    "    \n",
    "    plt.suptitle(f'Feature Importance Analysis - {city.title()}', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def save_ml_visualizations(city, results, city_data):\n",
    "    \"\"\"Save all visualizations for ML models\"\"\"\n",
    "    # Create visualization directory\n",
    "    viz_dir = f\"./results/ml_models/{city}/visualizations\"\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate and save plots\n",
    "    fig = plot_metrics_comparison(city, results)\n",
    "    fig.savefig(f\"{viz_dir}/metrics_comparison.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = plot_feature_importance(city, results)\n",
    "    fig.savefig(f\"{viz_dir}/feature_importance.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    # Plot predictions for each split\n",
    "    for split in ['val', 'test']:\n",
    "        # Get actual values from the data\n",
    "        actual_values = city_data[split]['AQI'].values\n",
    "        fig = plot_predictions(city, results, split, actual_values)\n",
    "        fig.savefig(f\"{viz_dir}/predictions_{split}.png\", bbox_inches='tight', dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First, let's load the preprocessed data for each city\n",
    "def load_city_data(city_name):\n",
    "    \"\"\"Load preprocessed data for a specific city\"\"\"\n",
    "    data_dir = \"../data/processed\"\n",
    "    city_data = {}\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        file_path = f\"{data_dir}/{city_name}/{split}.csv\"\n",
    "        # print(file_path)\n",
    "        if os.path.exists(file_path):\n",
    "            city_data[split] = pd.read_csv(file_path)\n",
    "            city_data[split]['date'] = pd.to_datetime(city_data[split]['Date'])\n",
    "    \n",
    "    return city_data\n",
    "\n",
    "def run_ml_analysis():\n",
    "    \"\"\"Run ML analysis for all cities\"\"\"\n",
    "    cities = ['bengaluru', 'chennai', 'delhi', 'hyderabad']\n",
    "    \n",
    "    for city in cities:\n",
    "        print(f\"\\nProcessing {city}...\")\n",
    "        \n",
    "        # Load city data\n",
    "        city_data = load_city_data(city)\n",
    "        if not city_data:\n",
    "            print(f\"No data found for {city}\")\n",
    "            continue\n",
    "        \n",
    "        # Evaluate all ML models\n",
    "        print(\"Evaluating ML models...\")\n",
    "        ml_results = evaluate_all_ml_models(city_data, city)\n",
    "        \n",
    "        # Save results\n",
    "        print(\"Saving results...\")\n",
    "        save_ml_results(city, ml_results)\n",
    "        \n",
    "        # Generate and save visualizations\n",
    "        print(\"Generating visualizations...\")\n",
    "        save_ml_visualizations(city, ml_results, city_data)\n",
    "        \n",
    "        # Print summary metrics\n",
    "        print(\"\\nModel Performance Summary:\")\n",
    "        for model_name, results in ml_results.items():\n",
    "            print(f\"\\n{model_name.replace('_', ' ').title()}:\")\n",
    "            for split in ['val', 'test']:\n",
    "                print(f\"{split.title()} Set:\")\n",
    "                print(f\"  RMSE: {results[split][f'{split}_rmse']:.2f}\")\n",
    "                print(f\"  MAE: {results[split][f'{split}_mae']:.2f}\")\n",
    "                print(f\"  R²: {results[split][f'{split}_r2']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Update the ModelResultsManager class to handle ML results\n",
    "class ModelResultsManager:\n",
    "    def __init__(self):\n",
    "        self.base_dir = \"./results\"\n",
    "        self.ml_dir = f\"{self.base_dir}/ml_models\"\n",
    "        self._create_directory_structure()\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        os.makedirs(self.ml_dir, exist_ok=True)\n",
    "        for city in ['bengaluru', 'chennai', 'delhi', 'hyderabad']:\n",
    "            city_dir = f\"{self.ml_dir}/{city}\"\n",
    "            os.makedirs(city_dir, exist_ok=True)\n",
    "            os.makedirs(f\"{city_dir}/visualizations\", exist_ok=True)\n",
    "    \n",
    "    def save_ml_results(self, city, results):\n",
    "        \"\"\"Save ML model results\"\"\"\n",
    "        city_dir = f\"{self.ml_dir}/{city}\"\n",
    "        \n",
    "        # Save results for each model\n",
    "        for model_name, model_results in results.items():\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            serializable_results = {\n",
    "                'validation': model_results['validation'],\n",
    "                'test': model_results['test'],\n",
    "                'predictions': model_results['predictions'],\n",
    "                'model_config': model_results['model_config']\n",
    "            }\n",
    "            \n",
    "            # Save to file\n",
    "            with open(f\"{city_dir}/{model_name}_results.json\", 'w') as f:\n",
    "                json.dump(serializable_results, f, indent=4)\n",
    "        \n",
    "        # Update metadata\n",
    "        self._update_metadata(city, results)\n",
    "    \n",
    "    def _update_metadata(self, city, results):\n",
    "        \"\"\"Update metadata file with ML model results\"\"\"\n",
    "        metadata_file = f\"{self.base_dir}/metadata.json\"\n",
    "        \n",
    "        # Load existing metadata\n",
    "        if os.path.exists(metadata_file):\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Update ML results\n",
    "        if 'ml_models' not in metadata:\n",
    "            metadata['ml_models'] = {}\n",
    "        \n",
    "        metadata['ml_models'][city] = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'models': list(results.keys()),\n",
    "            'metrics': {\n",
    "                model: {\n",
    "                    'validation': {\n",
    "                        'rmse': results[model]['validation'][f'val_rmse'],\n",
    "                        'mae': results[model]['validation'][f'val_mae'],\n",
    "                        'r2': results[model]['validation'][f'val_r2']\n",
    "                    },\n",
    "                    'test': {\n",
    "                        'rmse': results[model]['test'][f'test_rmse'],\n",
    "                        'mae': results[model]['test'][f'test_mae'],\n",
    "                        'r2': results[model]['test'][f'test_r2']\n",
    "                    }\n",
    "                }\n",
    "                for model in results\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bengaluru...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for bengaluru...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ridge for bengaluru...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for bengaluru...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for bengaluru...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for bengaluru...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for bengaluru...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for bengaluru...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(10.87013330823409), 'PM10': np.float64(9.343106906270908), 'NO': np.float64(3.948304968554416), 'NO2': np.float64(-0.5376059277925898), 'NOx': np.float64(1.1178416905950985), 'NH3': np.float64(0.1505847114882576), 'CO': np.float64(19.066827777192664), 'SO2': np.float64(-1.0413673503811367), 'O3': np.float64(5.233003353220542), 'Benzene': np.float64(-0.9977964972708125), 'Toluene': np.float64(-0.9410835880594363), 'tempmin': np.float64(-6.286577584122224), 'dew': np.float64(12.286618796219), 'humidity': np.float64(-11.365642027551617), 'precip': np.float64(-1.1832577023316233), 'precipprob': np.float64(0.45306695168593963), 'precipcover': np.float64(-1.4303463517218042), 'windgust': np.float64(0.24612338392867805), 'windspeed': np.float64(-0.111562946324548), 'winddir': np.float64(2.038215450857761), 'sealevelpressure': np.float64(-0.9683484797569628), 'cloudcover': np.float64(-3.253957082948485), 'visibility': np.float64(-4.591813683945387), 'solarradiation': np.float64(-4.536432212510011), 'moonphase': np.float64(-1.5103426771869604), 'StratoO3': np.float64(-0.35178693225210267), 'year': np.float64(-8.932876431905639), 'month': np.float64(-4.201937492875618), 'day': np.float64(-0.46784474240475893), 'dayofweek': np.float64(0.15768446919578272)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(10.86855972059306), 'PM10': np.float64(9.343587959716736), 'NO': np.float64(3.9459812362978917), 'NO2': np.float64(-0.53679487808658), 'NOx': np.float64(1.1185569205811825), 'NH3': np.float64(0.14952745257742545), 'CO': np.float64(19.066021327375868), 'SO2': np.float64(-1.0403942306904401), 'O3': np.float64(5.233484974094303), 'Benzene': np.float64(-0.9965162866634416), 'Toluene': np.float64(-0.9409587304031368), 'tempmin': np.float64(-6.264712914234685), 'dew': np.float64(12.24322916283575), 'humidity': np.float64(-11.325421423075312), 'precip': np.float64(-1.1839158010696487), 'precipprob': np.float64(0.45335498949011843), 'precipcover': np.float64(-1.429582861099516), 'windgust': np.float64(0.24516825167804598), 'windspeed': np.float64(-0.11180918754819177), 'winddir': np.float64(2.0379054906817413), 'sealevelpressure': np.float64(-0.9689136581141885), 'cloudcover': np.float64(-3.2553782149122843), 'visibility': np.float64(-4.589515844221904), 'solarradiation': np.float64(-4.52638090162699), 'moonphase': np.float64(-1.5104691538334423), 'StratoO3': np.float64(-0.3516568730765247), 'year': np.float64(-8.937497995239276), 'month': np.float64(-4.202690028335612), 'day': np.float64(-0.4681332116247883), 'dayofweek': np.float64(0.15731541440354202)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(10.69063281167155), 'PM10': np.float64(9.357394747670709), 'NO': np.float64(3.4678425638877326), 'NO2': np.float64(-0.08225735112874694), 'NOx': np.float64(1.050810516424559), 'NH3': np.float64(-0.0), 'CO': np.float64(19.08956961977909), 'SO2': np.float64(-0.7765873333785492), 'O3': np.float64(5.225539108154681), 'Benzene': np.float64(-0.73247915041937), 'Toluene': np.float64(-0.8759323304009595), 'tempmin': np.float64(-3.6602089964478193), 'dew': np.float64(7.19802205585419), 'humidity': np.float64(-6.689078483534552), 'precip': np.float64(-1.1439937654523868), 'precipprob': np.float64(0.0), 'precipcover': np.float64(-1.107337418591817), 'windgust': np.float64(0.018303711045263446), 'windspeed': np.float64(-0.0), 'winddir': np.float64(1.7623231819952714), 'sealevelpressure': np.float64(-0.79085421848903), 'cloudcover': np.float64(-2.5195827390590386), 'visibility': np.float64(-4.122397321272386), 'solarradiation': np.float64(-3.020936058693984), 'moonphase': np.float64(-1.4570587776385817), 'StratoO3': np.float64(-0.20639880184751974), 'year': np.float64(-9.212646360085138), 'month': np.float64(-4.104625980710888), 'day': np.float64(-0.383597078095856), 'dayofweek': np.float64(0.042024107444149854)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.18651431551929448), 'PM10': np.float64(0.10536372268628752), 'NO': np.float64(0.030752393680884317), 'NO2': np.float64(0.020943228630589856), 'NOx': np.float64(0.013825409545477537), 'NH3': np.float64(0.011021247985785998), 'CO': np.float64(0.3265128271295486), 'SO2': np.float64(0.019850990718477762), 'O3': np.float64(0.04392228458366637), 'Benzene': np.float64(0.017702684718536577), 'Toluene': np.float64(0.01903149172047752), 'tempmin': np.float64(0.016872269855613513), 'dew': np.float64(0.010749571925690609), 'humidity': np.float64(0.01335421537498835), 'precip': np.float64(0.013969524347830033), 'precipprob': np.float64(0.0001600344017266265), 'precipcover': np.float64(0.004119465878589544), 'windgust': np.float64(0.011337304031540835), 'windspeed': np.float64(0.01014586035146134), 'winddir': np.float64(0.013727953008578583), 'sealevelpressure': np.float64(0.011197418909864207), 'cloudcover': np.float64(0.015142112865529057), 'visibility': np.float64(0.016320830785651677), 'solarradiation': np.float64(0.01763938199487148), 'moonphase': np.float64(0.009854505032584027), 'StratoO3': np.float64(0.01161280440114921), 'year': np.float64(0.0035895433885429536), 'month': np.float64(0.006034477090497172), 'day': np.float64(0.0136926304440889), 'dayofweek': np.float64(0.0050394989921753765)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.24443554038576815), 'PM10': np.float64(0.13564367237474834), 'NO': np.float64(0.0057493786073259156), 'NO2': np.float64(0.002639607651954018), 'NOx': np.float64(0.011409716144382102), 'NH3': np.float64(0.0001646243975990191), 'CO': np.float64(0.46876823458069894), 'SO2': np.float64(0.0004591666077391598), 'O3': np.float64(0.049469373957340065), 'Benzene': np.float64(0.0014655189646238613), 'Toluene': np.float64(0.0054675727883512605), 'tempmin': np.float64(0.009828406691228642), 'dew': np.float64(0.0001731503970810108), 'humidity': np.float64(0.0035823268182620573), 'precip': np.float64(0.014396415423507345), 'precipprob': np.float64(0.0), 'precipcover': np.float64(0.00018354135067550628), 'windgust': np.float64(0.0005413248976861334), 'windspeed': np.float64(9.249062116782623e-05), 'winddir': np.float64(0.001582194427897581), 'sealevelpressure': np.float64(0.002917566423541432), 'cloudcover': np.float64(0.011586954182346077), 'visibility': np.float64(0.0063985773200393925), 'solarradiation': np.float64(0.006809797381736792), 'moonphase': np.float64(0.0005188083159990173), 'StratoO3': np.float64(0.003636516745760574), 'year': np.float64(0.010103978236823588), 'month': np.float64(0.0006158456680627929), 'day': np.float64(0.0011966342046538009), 'dayofweek': np.float64(0.00016306443299936204)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.1299209), 'PM10': np.float32(0.08776393), 'NO': np.float32(0.022063278), 'NO2': np.float32(0.0133207105), 'NOx': np.float32(0.025930583), 'NH3': np.float32(0.0), 'CO': np.float32(0.16341802), 'SO2': np.float32(0.030541554), 'O3': np.float32(0.052632146), 'Benzene': np.float32(0.013147831), 'Toluene': np.float32(0.02769126), 'tempmin': np.float32(0.030770877), 'dew': np.float32(0.0), 'humidity': np.float32(0.01873958), 'precip': np.float32(0.050193295), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.0), 'windgust': np.float32(0.03123695), 'windspeed': np.float32(0.0), 'winddir': np.float32(0.027681367), 'sealevelpressure': np.float32(0.025118895), 'cloudcover': np.float32(0.032505725), 'visibility': np.float32(0.03584834), 'solarradiation': np.float32(0.023559162), 'moonphase': np.float32(0.019665863), 'StratoO3': np.float32(0.023618946), 'year': np.float32(0.061402176), 'month': np.float32(0.03104131), 'day': np.float32(0.022187218), 'dayofweek': np.float32(0.0)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([11.75624537, 11.20235193,  3.1374911 , -2.03121723,  3.11236632,\n",
      "       -0.23588258, 28.04844751,  0.56816976,  6.1289068 , -1.87935354,\n",
      "       -3.14757744, -1.1852217 ,  0.93113878, -2.18230974, -0.42699985,\n",
      "        0.86736591,  0.1975543 , -1.08201528, -0.06347221,  1.80100965,\n",
      "        0.62449603, -0.98025178, -2.05443357, -0.76970215, -0.56631087,\n",
      "        0.04420951, -6.30181422, -2.26997183, -0.33473849,  1.66352387])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([11.75624537, 11.20235193,  3.1374911 , -2.03121723,  3.11236632,\n",
      "       -0.23588258, 28.04844751,  0.56816976,  6.1289068 , -1.87935354,\n",
      "       -3.14757744, -1.1852217 ,  0.93113878, -2.18230974, -0.42699985,\n",
      "        0.86736591,  0.1975543 , -1.08201528, -0.06347221,  1.80100965,\n",
      "        0.62449603, -0.98025178, -2.05443357, -0.76970215, -0.56631087,\n",
      "        0.04420951, -6.30181422, -2.26997183, -0.33473849,  1.66352387]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 21.93\n",
      "  MAE: 18.32\n",
      "  R²: 0.26\n",
      "Test Set:\n",
      "  RMSE: 17.99\n",
      "  MAE: 15.81\n",
      "  R²: 0.16\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 21.93\n",
      "  MAE: 18.33\n",
      "  R²: 0.26\n",
      "Test Set:\n",
      "  RMSE: 18.00\n",
      "  MAE: 15.81\n",
      "  R²: 0.16\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 22.52\n",
      "  MAE: 18.81\n",
      "  R²: 0.22\n",
      "Test Set:\n",
      "  RMSE: 18.59\n",
      "  MAE: 16.58\n",
      "  R²: 0.10\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 14.63\n",
      "  MAE: 11.48\n",
      "  R²: 0.67\n",
      "Test Set:\n",
      "  RMSE: 9.14\n",
      "  MAE: 6.75\n",
      "  R²: 0.78\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 16.24\n",
      "  MAE: 12.72\n",
      "  R²: 0.59\n",
      "Test Set:\n",
      "  RMSE: 10.49\n",
      "  MAE: 8.22\n",
      "  R²: 0.71\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 16.30\n",
      "  MAE: 12.69\n",
      "  R²: 0.59\n",
      "Test Set:\n",
      "  RMSE: 10.36\n",
      "  MAE: 8.16\n",
      "  R²: 0.72\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 19.58\n",
      "  MAE: 15.83\n",
      "  R²: 0.41\n",
      "Test Set:\n",
      "  RMSE: 16.32\n",
      "  MAE: 14.34\n",
      "  R²: 0.31\n",
      "\n",
      "Processing chennai...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for chennai...\n",
      "\n",
      "Evaluating ridge for chennai...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for chennai...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for chennai...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for chennai...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for chennai...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for chennai...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(30.102826843592577), 'PM10': np.float64(-0.8305473402367332), 'NO': np.float64(-5.1060169125912465), 'NO2': np.float64(3.9178325079226313), 'NOx': np.float64(2.825359515263982), 'NH3': np.float64(-3.80011422470902), 'CO': np.float64(18.656988893054457), 'SO2': np.float64(-1.2096895093867244), 'O3': np.float64(2.970790842057629), 'Benzene': np.float64(-1.0314217038630364), 'Toluene': np.float64(-0.7331581050080623), 'tempmin': np.float64(1.8878278341708221), 'dew': np.float64(-8.163733177746563), 'humidity': np.float64(2.5077367407341327), 'precip': np.float64(2.9517145996586978), 'precipprob': np.float64(1.1642933823458166), 'precipcover': np.float64(-1.3681946779195389), 'windgust': np.float64(-4.533301684905289), 'windspeed': np.float64(-1.4655420109944575), 'winddir': np.float64(0.19205989280395797), 'sealevelpressure': np.float64(-3.0278045701249408), 'cloudcover': np.float64(-1.1361473666962563), 'visibility': np.float64(-4.237839006999148), 'solarradiation': np.float64(2.553757640011313), 'moonphase': np.float64(1.9296774494009048), 'StratoO3': np.float64(-1.8039561918945322), 'year': np.float64(-9.082363550736241), 'month': np.float64(-1.16428288436764), 'day': np.float64(1.6455737036182752), 'dayofweek': np.float64(1.4927606741433281)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(27.130161927291578), 'PM10': np.float64(0.21371886144755764), 'NO': np.float64(-3.468702936316918), 'NO2': np.float64(3.5329392990647626), 'NOx': np.float64(2.177902493080453), 'NH3': np.float64(-3.11679477335833), 'CO': np.float64(16.82704909045648), 'SO2': np.float64(-0.6409655430267588), 'O3': np.float64(3.060141252528321), 'Benzene': np.float64(-0.8673552354681736), 'Toluene': np.float64(-0.42403820618310917), 'tempmin': np.float64(-1.4329159969088443), 'dew': np.float64(-4.323514768695202), 'humidity': np.float64(-1.1044246319258608), 'precip': np.float64(2.495753281571203), 'precipprob': np.float64(0.6772820152010743), 'precipcover': np.float64(-1.2577754327313146), 'windgust': np.float64(-3.7323441574928586), 'windspeed': np.float64(-1.7810426239188177), 'winddir': np.float64(0.7578212568086776), 'sealevelpressure': np.float64(-2.1903683281630943), 'cloudcover': np.float64(-0.9347575932289307), 'visibility': np.float64(-4.620587285643333), 'solarradiation': np.float64(1.4607661563364547), 'moonphase': np.float64(1.789187578038343), 'StratoO3': np.float64(-1.6738600626549316), 'year': np.float64(-9.531010123589041), 'month': np.float64(-1.6676420617217063), 'day': np.float64(1.3860388902286804), 'dayofweek': np.float64(1.348043864234521)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(23.780154405540777), 'PM10': np.float64(0.0), 'NO': np.float64(0.0), 'NO2': np.float64(0.0), 'NOx': np.float64(0.0), 'NH3': np.float64(-0.0), 'CO': np.float64(9.31932363133888), 'SO2': np.float64(0.0), 'O3': np.float64(0.0), 'Benzene': np.float64(0.0), 'Toluene': np.float64(0.0), 'tempmin': np.float64(-0.0), 'dew': np.float64(-0.0), 'humidity': np.float64(-0.0), 'precip': np.float64(0.0), 'precipprob': np.float64(-0.0), 'precipcover': np.float64(-0.0), 'windgust': np.float64(-0.0), 'windspeed': np.float64(-0.0), 'winddir': np.float64(-0.0), 'sealevelpressure': np.float64(0.0), 'cloudcover': np.float64(-0.0), 'visibility': np.float64(-0.0), 'solarradiation': np.float64(0.0), 'moonphase': np.float64(0.0), 'StratoO3': np.float64(-0.0), 'year': np.float64(-2.742583480092392), 'month': np.float64(-0.0), 'day': np.float64(0.0), 'dayofweek': np.float64(0.0)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.5306367573978289), 'PM10': np.float64(0.009554310600533989), 'NO': np.float64(0.025926942141900774), 'NO2': np.float64(0.024131890787466772), 'NOx': np.float64(0.015976684889457346), 'NH3': np.float64(0.008327160479234885), 'CO': np.float64(0.20130954092135464), 'SO2': np.float64(0.027479154314396768), 'O3': np.float64(0.018906629298015686), 'Benzene': np.float64(0.007831997444973881), 'Toluene': np.float64(0.00510994089611288), 'tempmin': np.float64(0.0062096356136605154), 'dew': np.float64(0.007412414428334183), 'humidity': np.float64(0.006728739667235163), 'precip': np.float64(0.00280278585047005), 'precipprob': np.float64(0.00028481560200993767), 'precipcover': np.float64(0.0006940987909971192), 'windgust': np.float64(0.0075973320065619784), 'windspeed': np.float64(0.007088990292887299), 'winddir': np.float64(0.008167587096312214), 'sealevelpressure': np.float64(0.007020238901767966), 'cloudcover': np.float64(0.004766774824542689), 'visibility': np.float64(0.007539872547192837), 'solarradiation': np.float64(0.010258138307822242), 'moonphase': np.float64(0.008341690215869753), 'StratoO3': np.float64(0.005802581720184604), 'year': np.float64(0.014511130156637192), 'month': np.float64(0.011752884788563284), 'day': np.float64(0.004876016789447869), 'dayofweek': np.float64(0.0029532632282266848)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.6513210002610508), 'PM10': np.float64(0.0025394063391968457), 'NO': np.float64(0.005025671931568483), 'NO2': np.float64(0.01529684375148728), 'NOx': np.float64(0.005298575053213455), 'NH3': np.float64(0.0035459751623631835), 'CO': np.float64(0.2395685001355704), 'SO2': np.float64(0.014243316441012474), 'O3': np.float64(0.006767769489608132), 'Benzene': np.float64(0.0), 'Toluene': np.float64(0.0), 'tempmin': np.float64(0.0006362935205960598), 'dew': np.float64(0.0008896950808353226), 'humidity': np.float64(0.004452312449890915), 'precip': np.float64(0.0), 'precipprob': np.float64(0.0), 'precipcover': np.float64(1.751335078305054e-06), 'windgust': np.float64(0.0014761649850754978), 'windspeed': np.float64(0.0), 'winddir': np.float64(8.327090607413273e-07), 'sealevelpressure': np.float64(0.0014360318046555502), 'cloudcover': np.float64(0.0), 'visibility': np.float64(0.006348083124654318), 'solarradiation': np.float64(0.0013204037997817091), 'moonphase': np.float64(0.0013339279842992343), 'StratoO3': np.float64(0.0), 'year': np.float64(0.02589307229831307), 'month': np.float64(0.012038590198529547), 'day': np.float64(0.0), 'dayofweek': np.float64(0.0005657821441587557)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.19476148), 'PM10': np.float32(0.0), 'NO': np.float32(0.05448742), 'NO2': np.float32(0.037981864), 'NOx': np.float32(0.04160519), 'NH3': np.float32(0.02992613), 'CO': np.float32(0.17616844), 'SO2': np.float32(0.055574343), 'O3': np.float32(0.021074878), 'Benzene': np.float32(0.0), 'Toluene': np.float32(0.0), 'tempmin': np.float32(0.029954832), 'dew': np.float32(0.028463624), 'humidity': np.float32(0.018148113), 'precip': np.float32(0.0), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.0), 'windgust': np.float32(0.026610577), 'windspeed': np.float32(0.0), 'winddir': np.float32(0.0), 'sealevelpressure': np.float32(0.014685504), 'cloudcover': np.float32(0.0), 'visibility': np.float32(0.030079246), 'solarradiation': np.float32(0.04070767), 'moonphase': np.float32(0.0), 'StratoO3': np.float32(0.0), 'year': np.float32(0.07456389), 'month': np.float32(0.07974113), 'day': np.float32(0.019392855), 'dayofweek': np.float32(0.026072845)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([ 22.92953596,   1.60063451,   0.27344315,   0.50049799,\n",
      "         0.45238017,  -2.1155478 ,  11.61084304,   1.20425791,\n",
      "         3.90504123,  -0.41691034,   1.19797349,  -2.04906646,\n",
      "        -3.31891629,  -1.74152673,   1.83359309,  -0.77994143,\n",
      "        -1.41587571,  -2.21563032,  -0.46648327,   0.92190751,\n",
      "        -0.28738625,  -1.62736491,  -4.95848737,   0.63397687,\n",
      "         1.17994703,  -0.51113792, -10.15789267,  -3.42717013,\n",
      "         0.7094958 ,   1.38655277])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([ 22.92953596,   1.60063451,   0.27344315,   0.50049799,\n",
      "         0.45238017,  -2.1155478 ,  11.61084304,   1.20425791,\n",
      "         3.90504123,  -0.41691034,   1.19797349,  -2.04906646,\n",
      "        -3.31891629,  -1.74152673,   1.83359309,  -0.77994143,\n",
      "        -1.41587571,  -2.21563032,  -0.46648327,   0.92190751,\n",
      "        -0.28738625,  -1.62736491,  -4.95848737,   0.63397687,\n",
      "         1.17994703,  -0.51113792, -10.15789267,  -3.42717013,\n",
      "         0.7094958 ,   1.38655277]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 25.37\n",
      "  MAE: 19.92\n",
      "  R²: 0.65\n",
      "Test Set:\n",
      "  RMSE: 30.14\n",
      "  MAE: 23.43\n",
      "  R²: 0.29\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 25.52\n",
      "  MAE: 19.78\n",
      "  R²: 0.65\n",
      "Test Set:\n",
      "  RMSE: 28.90\n",
      "  MAE: 22.14\n",
      "  R²: 0.35\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 25.14\n",
      "  MAE: 20.17\n",
      "  R²: 0.66\n",
      "Test Set:\n",
      "  RMSE: 25.27\n",
      "  MAE: 19.65\n",
      "  R²: 0.50\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 24.16\n",
      "  MAE: 17.96\n",
      "  R²: 0.69\n",
      "Test Set:\n",
      "  RMSE: 19.69\n",
      "  MAE: 13.95\n",
      "  R²: 0.70\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 23.46\n",
      "  MAE: 17.85\n",
      "  R²: 0.70\n",
      "Test Set:\n",
      "  RMSE: 22.48\n",
      "  MAE: 17.50\n",
      "  R²: 0.61\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 23.38\n",
      "  MAE: 17.71\n",
      "  R²: 0.71\n",
      "Test Set:\n",
      "  RMSE: 22.81\n",
      "  MAE: 17.79\n",
      "  R²: 0.60\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 28.29\n",
      "  MAE: 21.83\n",
      "  R²: 0.57\n",
      "Test Set:\n",
      "  RMSE: 31.46\n",
      "  MAE: 23.55\n",
      "  R²: 0.23\n",
      "\n",
      "Processing delhi...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for delhi...\n",
      "\n",
      "Evaluating ridge for delhi...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for delhi...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for delhi...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for delhi...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for delhi...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for delhi...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(51.639163439202875), 'PM10': np.float64(42.34135621993302), 'NO': np.float64(4.74527822779822), 'NO2': np.float64(-6.173658413521165), 'NOx': np.float64(9.425249599602962), 'NH3': np.float64(-6.935107230849825), 'CO': np.float64(5.626498358168566), 'SO2': np.float64(-0.16812399569880657), 'O3': np.float64(0.8131662262098699), 'Benzene': np.float64(-8.88490005334384), 'Toluene': np.float64(7.290762953460695), 'tempmin': np.float64(5.497532635079126), 'dew': np.float64(4.373848832266622), 'humidity': np.float64(-28.21807614103624), 'precip': np.float64(0.38378275227638126), 'precipprob': np.float64(-1.2125687721487544), 'precipcover': np.float64(2.7963458788482116), 'windgust': np.float64(6.098294317137605), 'windspeed': np.float64(0.9481104564295313), 'winddir': np.float64(0.6249950388791601), 'sealevelpressure': np.float64(13.639819461049935), 'cloudcover': np.float64(-8.812982724169986), 'visibility': np.float64(-14.706231133751166), 'solarradiation': np.float64(-11.73902164563614), 'moonphase': np.float64(0.5117636286818472), 'StratoO3': np.float64(0.8450087687865611), 'year': np.float64(-15.730064515168339), 'month': np.float64(-9.09539069795521), 'day': np.float64(-0.3484854634747383), 'dayofweek': np.float64(2.5359112753689526)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(50.66210490764299), 'PM10': np.float64(41.74748769744145), 'NO': np.float64(4.733953318457512), 'NO2': np.float64(-5.63307837288065), 'NOx': np.float64(9.395432052774193), 'NH3': np.float64(-6.716746310938028), 'CO': np.float64(5.862951083517863), 'SO2': np.float64(0.17036055300823022), 'O3': np.float64(1.1346547231417534), 'Benzene': np.float64(-8.041178708149227), 'Toluene': np.float64(6.901429679466796), 'tempmin': np.float64(7.364652828219287), 'dew': np.float64(0.8060206587197571), 'humidity': np.float64(-24.655623414024717), 'precip': np.float64(0.3335238098823727), 'precipprob': np.float64(-1.2563816396356104), 'precipcover': np.float64(2.5787111524757105), 'windgust': np.float64(5.986111167764997), 'windspeed': np.float64(1.0713937142463885), 'winddir': np.float64(0.6708317147103039), 'sealevelpressure': np.float64(12.72808058141892), 'cloudcover': np.float64(-8.743722817271642), 'visibility': np.float64(-14.31514810777677), 'solarradiation': np.float64(-10.423430403054859), 'moonphase': np.float64(0.5780955257573859), 'StratoO3': np.float64(0.8191512579739866), 'year': np.float64(-15.298337875755694), 'month': np.float64(-8.328419011172706), 'day': np.float64(-0.4099560512485376), 'dayofweek': np.float64(2.559756485272243)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(50.487184171191224), 'PM10': np.float64(40.96998558246011), 'NO': np.float64(0.0), 'NO2': np.float64(-0.0), 'NOx': np.float64(8.63976841034932), 'NH3': np.float64(-5.429348208420938), 'CO': np.float64(6.055942621835713), 'SO2': np.float64(0.0), 'O3': np.float64(0.0), 'Benzene': np.float64(-0.3509772861003317), 'Toluene': np.float64(2.014696256799518), 'tempmin': np.float64(0.0), 'dew': np.float64(-0.0), 'humidity': np.float64(-19.303513984390825), 'precip': np.float64(0.04737501492891322), 'precipprob': np.float64(-0.0), 'precipcover': np.float64(0.0), 'windgust': np.float64(4.223930906471104), 'windspeed': np.float64(0.6858279727474675), 'winddir': np.float64(0.20481742182033613), 'sealevelpressure': np.float64(7.829287247975099), 'cloudcover': np.float64(-4.066911776366913), 'visibility': np.float64(-10.531586743237272), 'solarradiation': np.float64(-3.5681590064755455), 'moonphase': np.float64(0.0), 'StratoO3': np.float64(0.07943009760808832), 'year': np.float64(-13.460308419570802), 'month': np.float64(-4.6956119720476), 'day': np.float64(-0.0), 'dayofweek': np.float64(1.8097437588638239)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.7316665592930203), 'PM10': np.float64(0.10864805398838782), 'NO': np.float64(0.0029639960331093677), 'NO2': np.float64(0.00572918880938612), 'NOx': np.float64(0.025962674358104385), 'NH3': np.float64(0.004879449402124706), 'CO': np.float64(0.019407276994622105), 'SO2': np.float64(0.004213931187268095), 'O3': np.float64(0.007702450289293778), 'Benzene': np.float64(0.0036807622392930404), 'Toluene': np.float64(0.038636874224626326), 'tempmin': np.float64(0.003038414178216752), 'dew': np.float64(0.0051713684072369134), 'humidity': np.float64(0.0034080287589171587), 'precip': np.float64(0.00034644691043042027), 'precipprob': np.float64(8.955283574777808e-05), 'precipcover': np.float64(0.0001323468327667544), 'windgust': np.float64(0.0024948698394841222), 'windspeed': np.float64(0.0024108590981072988), 'winddir': np.float64(0.0029154722272455693), 'sealevelpressure': np.float64(0.0029858308328997653), 'cloudcover': np.float64(0.002296477842891345), 'visibility': np.float64(0.0019208126982207848), 'solarradiation': np.float64(0.0029463754887732565), 'moonphase': np.float64(0.0021210306827651), 'StratoO3': np.float64(0.003332219534643062), 'year': np.float64(0.006658318721604817), 'month': np.float64(0.0006076809917889598), 'day': np.float64(0.0020877109304415307), 'dayofweek': np.float64(0.0015449663685825493)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.7157278624612827), 'PM10': np.float64(0.12596385104901803), 'NO': np.float64(0.0026206647218254063), 'NO2': np.float64(0.004128920835951502), 'NOx': np.float64(0.016516204183831373), 'NH3': np.float64(0.003906732136419914), 'CO': np.float64(0.02224613232251169), 'SO2': np.float64(0.003319304480008665), 'O3': np.float64(0.0076656471420329), 'Benzene': np.float64(0.0028365880544881815), 'Toluene': np.float64(0.032760609639413255), 'tempmin': np.float64(0.0023810994952485724), 'dew': np.float64(0.006869265668508413), 'humidity': np.float64(0.0062733492119149805), 'precip': np.float64(0.00023841882331364754), 'precipprob': np.float64(9.987805383569082e-05), 'precipcover': np.float64(0.00025933598765121247), 'windgust': np.float64(0.0032125546841471797), 'windspeed': np.float64(0.0019103340781302177), 'winddir': np.float64(0.002364457846413481), 'sealevelpressure': np.float64(0.0033543419526528367), 'cloudcover': np.float64(0.0016564814566920859), 'visibility': np.float64(0.0007944950870578526), 'solarradiation': np.float64(0.0036943641153057132), 'moonphase': np.float64(0.0018100495088767858), 'StratoO3': np.float64(0.002443003470270797), 'year': np.float64(0.0227794318851281), 'month': np.float64(0.0011583189207639085), 'day': np.float64(0.000367218234519948), 'dayofweek': np.float64(0.000641084492784804)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.4328378), 'PM10': np.float32(0.13010877), 'NO': np.float32(0.003338334), 'NO2': np.float32(0.0063279457), 'NOx': np.float32(0.021218594), 'NH3': np.float32(0.0068899645), 'CO': np.float32(0.04352564), 'SO2': np.float32(0.0063229403), 'O3': np.float32(0.011702483), 'Benzene': np.float32(0.0071673826), 'Toluene': np.float32(0.08595977), 'tempmin': np.float32(0.008349829), 'dew': np.float32(0.01477855), 'humidity': np.float32(0.016727334), 'precip': np.float32(0.0038515613), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.00548038), 'windgust': np.float32(0.0051985155), 'windspeed': np.float32(0.0059452564), 'winddir': np.float32(0.0051923553), 'sealevelpressure': np.float32(0.008586959), 'cloudcover': np.float32(0.0051378966), 'visibility': np.float32(0.0063724965), 'solarradiation': np.float32(0.00659669), 'moonphase': np.float32(0.003252804), 'StratoO3': np.float32(0.0035327075), 'year': np.float32(0.13228267), 'month': np.float32(0.0054140557), 'day': np.float32(0.0032861293), 'dayofweek': np.float32(0.004614171)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([ 54.81156087,  44.02274915,  -3.0228901 ,  -1.37130157,\n",
      "        11.28896056,  -6.75390435,   7.13484941,   2.4125782 ,\n",
      "        -1.89269119,  -9.18565303,   5.31967477,   2.07102368,\n",
      "         5.92199132, -24.95054564,  -0.10011229,  -2.235905  ,\n",
      "         1.8047375 ,   4.18976269,   2.03780299,  -0.92025931,\n",
      "        10.2987371 ,  -7.90632937, -17.34842755,  -9.89859236,\n",
      "        -0.48143044,   0.19251841, -14.28463194,  -8.6262405 ,\n",
      "        -0.81760368,   2.7309614 ])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([ 54.81156087,  44.02274915,  -3.0228901 ,  -1.37130157,\n",
      "        11.28896056,  -6.75390435,   7.13484941,   2.4125782 ,\n",
      "        -1.89269119,  -9.18565303,   5.31967477,   2.07102368,\n",
      "         5.92199132, -24.95054564,  -0.10011229,  -2.235905  ,\n",
      "         1.8047375 ,   4.18976269,   2.03780299,  -0.92025931,\n",
      "        10.2987371 ,  -7.90632937, -17.34842755,  -9.89859236,\n",
      "        -0.48143044,   0.19251841, -14.28463194,  -8.6262405 ,\n",
      "        -0.81760368,   2.7309614 ]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 34.59\n",
      "  MAE: 26.79\n",
      "  R²: 0.91\n",
      "Test Set:\n",
      "  RMSE: 33.56\n",
      "  MAE: 24.28\n",
      "  R²: 0.91\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 34.20\n",
      "  MAE: 26.47\n",
      "  R²: 0.91\n",
      "Test Set:\n",
      "  RMSE: 33.17\n",
      "  MAE: 23.98\n",
      "  R²: 0.91\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 32.20\n",
      "  MAE: 23.49\n",
      "  R²: 0.92\n",
      "Test Set:\n",
      "  RMSE: 33.78\n",
      "  MAE: 23.75\n",
      "  R²: 0.91\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 29.02\n",
      "  MAE: 21.79\n",
      "  R²: 0.94\n",
      "Test Set:\n",
      "  RMSE: 29.51\n",
      "  MAE: 23.63\n",
      "  R²: 0.93\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 29.36\n",
      "  MAE: 21.22\n",
      "  R²: 0.94\n",
      "Test Set:\n",
      "  RMSE: 27.61\n",
      "  MAE: 21.07\n",
      "  R²: 0.94\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 29.46\n",
      "  MAE: 21.22\n",
      "  R²: 0.94\n",
      "Test Set:\n",
      "  RMSE: 28.24\n",
      "  MAE: 20.88\n",
      "  R²: 0.94\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 31.48\n",
      "  MAE: 23.16\n",
      "  R²: 0.93\n",
      "Test Set:\n",
      "  RMSE: 32.12\n",
      "  MAE: 23.02\n",
      "  R²: 0.92\n",
      "\n",
      "Processing hyderabad...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for hyderabad...\n",
      "\n",
      "Evaluating ridge for hyderabad...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for hyderabad...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for hyderabad...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for hyderabad...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for hyderabad...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for hyderabad...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(39.30934770698309), 'PM10': np.float64(12.700804126616145), 'NO': np.float64(1.8732454760805979), 'NO2': np.float64(-4.876202420132718), 'NOx': np.float64(-2.9348851799722366), 'NH3': np.float64(4.083512166642951), 'CO': np.float64(14.813787015460049), 'SO2': np.float64(-4.346722420952267), 'O3': np.float64(7.3842902107617086), 'Benzene': np.float64(-6.773294492386531), 'Toluene': np.float64(5.581356487781196), 'tempmin': np.float64(-6.611314728902171), 'dew': np.float64(2.6673352045008496), 'humidity': np.float64(0.9808056684903946), 'precip': np.float64(-1.1258194679489089), 'precipprob': np.float64(0.28855054866007673), 'precipcover': np.float64(-2.355153221727194), 'windgust': np.float64(-1.0489910922532135), 'windspeed': np.float64(-0.6588053778897949), 'winddir': np.float64(3.3041565032539983), 'sealevelpressure': np.float64(-5.42977633088199), 'cloudcover': np.float64(1.9012988747493411), 'visibility': np.float64(-3.670394469320923), 'solarradiation': np.float64(2.746475159274517), 'moonphase': np.float64(0.44094634787527054), 'StratoO3': np.float64(-0.146532554796172), 'year': np.float64(-10.321619861902242), 'month': np.float64(-3.2168560858044515), 'day': np.float64(-1.3241259025269836), 'dayofweek': np.float64(0.03427596417305734)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(38.98162400727589), 'PM10': np.float64(12.403226320997465), 'NO': np.float64(1.8565045631900063), 'NO2': np.float64(-4.815625302094871), 'NOx': np.float64(-2.8216035069288328), 'NH3': np.float64(3.9695884477399423), 'CO': np.float64(14.625609905970295), 'SO2': np.float64(-4.120646522055129), 'O3': np.float64(7.099062821438395), 'Benzene': np.float64(-5.549409216025603), 'Toluene': np.float64(4.375893170924716), 'tempmin': np.float64(-5.979290519354322), 'dew': np.float64(2.0528517640096773), 'humidity': np.float64(1.2626997344136086), 'precip': np.float64(-1.116005266698451), 'precipprob': np.float64(0.3218315600474652), 'precipcover': np.float64(-2.276549580199111), 'windgust': np.float64(-1.0787366624337962), 'windspeed': np.float64(-0.6542019431062998), 'winddir': np.float64(3.171868209061173), 'sealevelpressure': np.float64(-5.067373004354597), 'cloudcover': np.float64(1.7321941995993189), 'visibility': np.float64(-3.6878867287636834), 'solarradiation': np.float64(2.7125667847048818), 'moonphase': np.float64(0.3981812439853124), 'StratoO3': np.float64(-0.11978146534386064), 'year': np.float64(-10.111486440792524), 'month': np.float64(-3.210484401994413), 'day': np.float64(-1.2808666122379808), 'dayofweek': np.float64(0.061608200906474245)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(39.277084229595765), 'PM10': np.float64(12.107771694144846), 'NO': np.float64(1.6794261268132442), 'NO2': np.float64(-4.3928437514255405), 'NOx': np.float64(-2.6109480537635363), 'NH3': np.float64(3.6102088418938156), 'CO': np.float64(14.60178259702764), 'SO2': np.float64(-3.853556341270508), 'O3': np.float64(6.831129873704875), 'Benzene': np.float64(-4.106589095664025), 'Toluene': np.float64(2.7582099566638703), 'tempmin': np.float64(-5.185200305083844), 'dew': np.float64(1.7520051140972124), 'humidity': np.float64(1.1889650632217326), 'precip': np.float64(-0.9075149759840779), 'precipprob': np.float64(0.19352166938769796), 'precipcover': np.float64(-2.1066173097933625), 'windgust': np.float64(-0.8516950754291922), 'windspeed': np.float64(-0.581780660030746), 'winddir': np.float64(3.019921235301579), 'sealevelpressure': np.float64(-4.649684111213142), 'cloudcover': np.float64(1.2253808826244235), 'visibility': np.float64(-3.702953468425895), 'solarradiation': np.float64(2.26509546694486), 'moonphase': np.float64(0.28176758440833927), 'StratoO3': np.float64(-0.0), 'year': np.float64(-9.86921725663627), 'month': np.float64(-3.0994948502650868), 'day': np.float64(-1.2212477334972343), 'dayofweek': np.float64(0.025336157041935266)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.6818646350768899), 'PM10': np.float64(0.022302881370935793), 'NO': np.float64(0.0065206288911362435), 'NO2': np.float64(0.017551140735574556), 'NOx': np.float64(0.005925263902375551), 'NH3': np.float64(0.00797767135784298), 'CO': np.float64(0.09078759173830526), 'SO2': np.float64(0.006170316140280428), 'O3': np.float64(0.029645039532829827), 'Benzene': np.float64(0.003986669724653007), 'Toluene': np.float64(0.007668069378871539), 'tempmin': np.float64(0.005849906365977484), 'dew': np.float64(0.00501351838035151), 'humidity': np.float64(0.006273847879700556), 'precip': np.float64(0.005003082474578427), 'precipprob': np.float64(0.0002277612904728118), 'precipcover': np.float64(0.003424770385304967), 'windgust': np.float64(0.013277026003390927), 'windspeed': np.float64(0.005959726138428719), 'winddir': np.float64(0.011732729464968027), 'sealevelpressure': np.float64(0.01416991842640133), 'cloudcover': np.float64(0.006863894277384039), 'visibility': np.float64(0.003592722714167908), 'solarradiation': np.float64(0.005918461460145253), 'moonphase': np.float64(0.007945054871296051), 'StratoO3': np.float64(0.008955355018528306), 'year': np.float64(0.004255301395166761), 'month': np.float64(0.0019583407777794258), 'day': np.float64(0.005509015854526183), 'dayofweek': np.float64(0.003669658971736149)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.7086995462294903), 'PM10': np.float64(0.019944552708817155), 'NO': np.float64(0.003102090654157115), 'NO2': np.float64(0.009946342579357802), 'NOx': np.float64(0.0015773014396187155), 'NH3': np.float64(0.004074336400882973), 'CO': np.float64(0.09618816588906069), 'SO2': np.float64(0.004578491327542555), 'O3': np.float64(0.04506503591537688), 'Benzene': np.float64(0.009387205052532372), 'Toluene': np.float64(0.00565821783969292), 'tempmin': np.float64(0.004506199959897414), 'dew': np.float64(0.009604674133890254), 'humidity': np.float64(0.002136027849744732), 'precip': np.float64(0.0013712600237123689), 'precipprob': np.float64(0.0), 'precipcover': np.float64(0.00036880892762443217), 'windgust': np.float64(0.012264938695544726), 'windspeed': np.float64(0.005053743847561158), 'winddir': np.float64(0.010914655503015739), 'sealevelpressure': np.float64(0.00616438871723241), 'cloudcover': np.float64(0.009228613638302855), 'visibility': np.float64(0.0022240931045704533), 'solarradiation': np.float64(0.0040031274883584695), 'moonphase': np.float64(0.00301725355813129), 'StratoO3': np.float64(0.0030246007213103445), 'year': np.float64(0.01334593602471781), 'month': np.float64(0.0036354678726614386), 'day': np.float64(0.0008345886616256288), 'dayofweek': np.float64(8.033523556901817e-05)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.34181118), 'PM10': np.float32(0.033792153), 'NO': np.float32(0.009051764), 'NO2': np.float32(0.017503388), 'NOx': np.float32(0.0163744), 'NH3': np.float32(0.024208453), 'CO': np.float32(0.09311908), 'SO2': np.float32(0.0089451885), 'O3': np.float32(0.024663407), 'Benzene': np.float32(0.011843375), 'Toluene': np.float32(0.013782819), 'tempmin': np.float32(0.011226225), 'dew': np.float32(0.10072954), 'humidity': np.float32(0.016721252), 'precip': np.float32(0.024872202), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.0043717236), 'windgust': np.float32(0.013937702), 'windspeed': np.float32(0.008024211), 'winddir': np.float32(0.030456847), 'sealevelpressure': np.float32(0.03769183), 'cloudcover': np.float32(0.012753405), 'visibility': np.float32(0.013665033), 'solarradiation': np.float32(0.030942129), 'moonphase': np.float32(0.007181653), 'StratoO3': np.float32(0.022848245), 'year': np.float32(0.048433147), 'month': np.float32(0.0123962425), 'day': np.float32(0.005807413), 'dayofweek': np.float32(0.002846061)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([ 3.44889852e+01,  1.45545367e+01,  3.61101343e+00, -3.72304324e+00,\n",
      "       -3.86937504e+00,  2.61970154e+00,  1.43889613e+01, -2.92342934e+00,\n",
      "        7.39988087e+00, -2.21431470e+00,  2.45812568e+00, -3.21642688e+00,\n",
      "        1.20189587e+00, -8.53686328e-01,  2.32604312e-01,  4.99412834e-01,\n",
      "        7.03764733e-01,  1.23066598e-01, -1.20709493e-01,  2.41719301e+00,\n",
      "       -3.73223554e+00,  9.21964321e-01, -2.65426984e+00,  1.63778843e+00,\n",
      "        8.61064139e-01,  1.97599871e-02, -7.11611314e+00, -2.35896646e+00,\n",
      "       -1.22986679e+00, -5.57437607e-01])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([ 3.44889852e+01,  1.45545367e+01,  3.61101343e+00, -3.72304324e+00,\n",
      "       -3.86937504e+00,  2.61970154e+00,  1.43889613e+01, -2.92342934e+00,\n",
      "        7.39988087e+00, -2.21431470e+00,  2.45812568e+00, -3.21642688e+00,\n",
      "        1.20189587e+00, -8.53686328e-01,  2.32604312e-01,  4.99412834e-01,\n",
      "        7.03764733e-01,  1.23066598e-01, -1.20709493e-01,  2.41719301e+00,\n",
      "       -3.73223554e+00,  9.21964321e-01, -2.65426984e+00,  1.63778843e+00,\n",
      "        8.61064139e-01,  1.97599871e-02, -7.11611314e+00, -2.35896646e+00,\n",
      "       -1.22986679e+00, -5.57437607e-01]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 17.39\n",
      "  MAE: 14.73\n",
      "  R²: 0.57\n",
      "Test Set:\n",
      "  RMSE: 19.27\n",
      "  MAE: 15.54\n",
      "  R²: 0.71\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 17.22\n",
      "  MAE: 14.66\n",
      "  R²: 0.58\n",
      "Test Set:\n",
      "  RMSE: 18.57\n",
      "  MAE: 14.82\n",
      "  R²: 0.73\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 17.00\n",
      "  MAE: 14.49\n",
      "  R²: 0.59\n",
      "Test Set:\n",
      "  RMSE: 17.74\n",
      "  MAE: 14.01\n",
      "  R²: 0.75\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 11.44\n",
      "  MAE: 9.24\n",
      "  R²: 0.81\n",
      "Test Set:\n",
      "  RMSE: 15.63\n",
      "  MAE: 12.93\n",
      "  R²: 0.81\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 9.95\n",
      "  MAE: 7.81\n",
      "  R²: 0.86\n",
      "Test Set:\n",
      "  RMSE: 13.74\n",
      "  MAE: 11.55\n",
      "  R²: 0.85\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 9.59\n",
      "  MAE: 7.68\n",
      "  R²: 0.87\n",
      "Test Set:\n",
      "  RMSE: 15.44\n",
      "  MAE: 12.32\n",
      "  R²: 0.81\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 14.49\n",
      "  MAE: 12.13\n",
      "  R²: 0.70\n",
      "Test Set:\n",
      "  RMSE: 15.86\n",
      "  MAE: 12.22\n",
      "  R²: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Initialize results manager\n",
    "results_manager = ModelResultsManager()\n",
    "\n",
    "# Run ML analysis\n",
    "run_ml_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
