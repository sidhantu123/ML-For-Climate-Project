{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import stats\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "# # Set visualization style\n",
    "# plt.style.use('seaborn')\n",
    "# sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features for bengaluru train set\n",
      "Creating lag features for bengaluru val set\n",
      "Creating lag features for bengaluru test set\n",
      "\n",
      "Bengaluru data loaded:\n",
      "Train: 1241 samples\n",
      "Validation: 287 samples\n",
      "Test: 382 samples\n",
      "Creating lag features for chennai train set\n",
      "Creating lag features for chennai val set\n",
      "Creating lag features for chennai test set\n",
      "\n",
      "Chennai data loaded:\n",
      "Train: 1224 samples\n",
      "Validation: 283 samples\n",
      "Test: 377 samples\n",
      "Creating lag features for delhi train set\n",
      "Creating lag features for delhi val set\n",
      "Creating lag features for delhi test set\n",
      "\n",
      "Delhi data loaded:\n",
      "Train: 1299 samples\n",
      "Validation: 300 samples\n",
      "Test: 400 samples\n",
      "Creating lag features for hyderabad train set\n",
      "Creating lag features for hyderabad val set\n",
      "Creating lag features for hyderabad test set\n",
      "\n",
      "Hyderabad data loaded:\n",
      "Train: 1222 samples\n",
      "Validation: 282 samples\n",
      "Test: 376 samples\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(data, target_col='AQI', n_lags=7):\n",
    "    \"\"\"Create lag features for the target column\"\"\"\n",
    "    data = data.sort_values('Date')\n",
    "    for i in range(1, n_lags + 1):\n",
    "        data[f'{target_col}_lag_{i}'] = data[target_col].shift(i)\n",
    "    return data\n",
    "\n",
    "# Cell 2: Load pre-split data for each city\n",
    "processed_dir = '../data/processed'\n",
    "cities = ['bengaluru', 'chennai', 'delhi', 'hyderabad']\n",
    "\n",
    "# Dictionary to store data for each city\n",
    "city_data = {}\n",
    "\n",
    "for city in cities:\n",
    "    city_dir = f'{processed_dir}/{city.lower()}'\n",
    "    city_data[city] = {\n",
    "        'train': pd.read_csv(f'{city_dir}/train.csv'),\n",
    "        'val': pd.read_csv(f'{city_dir}/val.csv'),\n",
    "        'test': pd.read_csv(f'{city_dir}/test.csv')\n",
    "    }\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        city_data[city][split]['Date'] = pd.to_datetime(city_data[city][split]['Date'])\n",
    "        \n",
    "        # Check if lag features exist, if not create them\n",
    "        if 'AQI_lag_1' not in city_data[city][split].columns:\n",
    "            print(f\"Creating lag features for {city} {split} set\")\n",
    "            city_data[city][split] = create_lag_features(city_data[city][split])\n",
    "    \n",
    "    print(f\"\\n{city.title()} data loaded:\")\n",
    "    print(f\"Train: {city_data[city]['train'].shape[0]} samples\")\n",
    "    print(f\"Validation: {city_data[city]['val'].shape[0]} samples\")\n",
    "    print(f\"Test: {city_data[city]['test'].shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define utility functions\n",
    "def calculate_metrics(y_true, y_pred, prefix=''):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics with confidence intervals\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Remove any NaN values from both arrays\n",
    "    mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        print(\"Warning: No valid data points after removing NaN values\")\n",
    "        return {f'{prefix}rmse': np.nan, f'{prefix}mae': np.nan, f'{prefix}r2': np.nan}\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    metrics[f'{prefix}rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    metrics[f'{prefix}mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics[f'{prefix}r2'] = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate confidence intervals using bootstrap\n",
    "    n_iterations = 1000\n",
    "    n_samples = len(y_true)\n",
    "    \n",
    "    # Initialize arrays to store bootstrap metrics\n",
    "    rmse_boots = np.zeros(n_iterations)\n",
    "    mae_boots = np.zeros(n_iterations)\n",
    "    r2_boots = np.zeros(n_iterations)\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # Sample with replacement\n",
    "        indices = np.random.randint(0, n_samples, n_samples)\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_pred_boot = y_pred[indices]\n",
    "        \n",
    "        # Calculate metrics for this bootstrap sample\n",
    "        rmse_boots[i] = np.sqrt(mean_squared_error(y_true_boot, y_pred_boot))\n",
    "        mae_boots[i] = mean_absolute_error(y_true_boot, y_pred_boot)\n",
    "        r2_boots[i] = r2_score(y_true_boot, y_pred_boot)\n",
    "    \n",
    "    # Calculate 95% confidence intervals\n",
    "    for metric_name, metric_boots in [('rmse', rmse_boots), ('mae', mae_boots), ('r2', r2_boots)]:\n",
    "        lower, upper = np.percentile(metric_boots, [2.5, 97.5])\n",
    "        metrics[f'{prefix}{metric_name}_ci'] = (lower, upper)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    \"\"\"Print metrics in a formatted way\"\"\"\n",
    "    if isinstance(metrics, tuple):\n",
    "        # Handle confidence intervals\n",
    "        print(f\"({metrics[0]:.3f}, {metrics[1]:.3f})\")\n",
    "    elif isinstance(metrics, dict):\n",
    "        # Handle metric dictionaries\n",
    "        for metric_name, value in metrics.items():\n",
    "            if isinstance(value, tuple):\n",
    "                print(f\"{metric_name}: ({value[0]:.3f}, {value[1]:.3f})\")\n",
    "            else:\n",
    "                print(f\"{metric_name}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"Unknown metric type: {type(metrics)}\")\n",
    "\n",
    "def plot_metrics_comparison(city, results):\n",
    "    \"\"\"Plot comparison of metrics for different models\"\"\"\n",
    "    models = ['persistence', 'moving_average']\n",
    "    metrics = ['rmse', 'mae', 'r2']\n",
    "    splits = ['validation', 'test']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        # Get values and confidence intervals for each split\n",
    "        values = {split: [] for split in splits}\n",
    "        cis = {split: [] for split in splits}\n",
    "        \n",
    "        for model in models:\n",
    "            for split in splits:\n",
    "                metric_key = f'{split[:3]}_{metric}'\n",
    "                ci_key = f'{split[:3]}_{metric}_ci'\n",
    "                \n",
    "                if split in results[model] and metric_key in results[model][split]:\n",
    "                    values[split].append(results[model][split][metric_key])\n",
    "                    cis[split].append(results[model][split][ci_key])\n",
    "        \n",
    "        # Only plot if we have data\n",
    "        if any(values[split] for split in splits):\n",
    "            # Plot bars with error bars for each split\n",
    "            x = np.arange(len(models))\n",
    "            width = 0.35\n",
    "            \n",
    "            for i, split in enumerate(splits):\n",
    "                if values[split]:  # Only plot if we have values\n",
    "                    axes[idx].bar(x + i*width, values[split], width,\n",
    "                                yerr=[(v-ci[0], ci[1]-v) for v, ci in zip(values[split], cis[split])],\n",
    "                                label=split.title(), capsize=5, alpha=0.7)\n",
    "            \n",
    "            axes[idx].set_xticks(x + width/2)\n",
    "            axes[idx].set_xticklabels([m.replace('_', ' ').title() for m in models])\n",
    "            axes[idx].set_title(f'{metric.upper()} Comparison')\n",
    "            axes[idx].set_ylabel(metric.upper())\n",
    "            axes[idx].legend()\n",
    "        else:\n",
    "            # If no data, show a message\n",
    "            axes[idx].text(0.5, 0.5, 'No data available',\n",
    "                         horizontalalignment='center',\n",
    "                         verticalalignment='center',\n",
    "                         transform=axes[idx].transAxes)\n",
    "            axes[idx].set_title(f'{metric.upper()} Comparison')\n",
    "    \n",
    "    plt.suptitle(f'Model Performance Comparison - {city.title()}', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_predictions(city, results, data_split='test'):\n",
    "    \"\"\"Plot predictions from baseline models\"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Get actual values\n",
    "    actual = city_data[city][data_split]['AQI']\n",
    "    dates = city_data[city][data_split]['Date']\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(dates, actual, label='Actual', color='black', alpha=0.6)\n",
    "    \n",
    "    # Plot predictions for each model\n",
    "    for model_name, color in [('persistence', 'blue'), ('moving_average', 'red')]:\n",
    "        predictions = results[model_name]['predictions'][data_split]\n",
    "        plt.plot(dates, predictions, \n",
    "                label=model_name.replace('_', ' ').title(),\n",
    "                color=color, alpha=0.6)\n",
    "    \n",
    "    plt.title(f'{city.title()} - {data_split.title()} Set Predictions')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('AQI')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_feature_importance(city, results):\n",
    "    \"\"\"Plot feature importance for models that support it\"\"\"\n",
    "    # Get models with feature importance\n",
    "    models_with_importance = {\n",
    "        name: results[name]['model_config']['feature_importance']\n",
    "        for name in results\n",
    "        if results[name]['model_config']['feature_importance'] is not None\n",
    "    }\n",
    "    \n",
    "    if not models_with_importance:\n",
    "        print(\"No models with feature importance found\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    n_models = len(models_with_importance)\n",
    "    fig, axes = plt.subplots(n_models, 1, figsize=(15, 5*n_models))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (model_name, importance) in enumerate(models_with_importance.items()):\n",
    "        # Sort features by importance\n",
    "        sorted_features = sorted(importance.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "        features, values = zip(*sorted_features)\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = axes[idx].barh(features, values)\n",
    "        \n",
    "        # Color bars based on sign\n",
    "        for bar in bars:\n",
    "            if bar.get_width() < 0:\n",
    "                bar.set_color('red')\n",
    "            else:\n",
    "                bar.set_color('blue')\n",
    "        \n",
    "        # Add vertical line at x=0\n",
    "        axes[idx].axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        axes[idx].set_title(f'Feature Importance - {model_name.replace(\"_\", \" \").title()}')\n",
    "        axes[idx].set_xlabel('Importance')\n",
    "        axes[idx].set_ylabel('Features')\n",
    "    \n",
    "    plt.suptitle(f'Feature Importance Analysis - {city.title()}', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Define baseline models\n",
    "class PersistenceModel:\n",
    "    def __init__(self):\n",
    "        self.name = \"Persistence\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # No training needed for persistence model\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # For persistence model, we'll use the 1-day lag if it exists\n",
    "        if 'AQI_lag_1' not in X.columns:\n",
    "            raise ValueError(\"AQI_lag_1 feature not found in the data\")\n",
    "        return X['AQI_lag_1'].values\n",
    "\n",
    "class MovingAverageModel:\n",
    "    def __init__(self, window_size=7):\n",
    "        self.name = \"Moving Average\"\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # No training needed for moving average model\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Create a rolling window of lag features\n",
    "        lag_cols = [f'AQI_lag_{i}' for i in range(1, self.window_size + 1)]\n",
    "        if not all(col in X.columns for col in lag_cols):\n",
    "            raise ValueError(f\"Required lag features not found in the data\")\n",
    "        \n",
    "        # Calculate moving average\n",
    "        lag_values = X[lag_cols].values\n",
    "        return np.nanmean(lag_values, axis=1)  # Use nanmean to handle NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Function to evaluate baseline models\n",
    "def evaluate_baseline_models(city_data, city_name):\n",
    "    \"\"\"Evaluate baseline models for a specific city\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Initialize models\n",
    "    persistence = PersistenceModel()\n",
    "    moving_avg = MovingAverageModel(window_size=7)\n",
    "    \n",
    "    # Fit and evaluate persistence model\n",
    "    persistence.fit(city_data['train'], city_data['train']['AQI'])\n",
    "    val_pred_persistence = persistence.predict(city_data['val'])\n",
    "    test_pred_persistence = persistence.predict(city_data['test'])\n",
    "\n",
    "    # Calculate feature importance for persistence model\n",
    "    # For persistence, the importance is 1 for lag_1 and 0 for others\n",
    "    persistence_importance = {\n",
    "        'AQI_lag_1': 1.0,\n",
    "        'AQI_lag_2': 0.0,\n",
    "        'AQI_lag_3': 0.0,\n",
    "        'AQI_lag_4': 0.0,\n",
    "        'AQI_lag_5': 0.0,\n",
    "        'AQI_lag_6': 0.0,\n",
    "        'AQI_lag_7': 0.0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Fit and evaluate moving average model\n",
    "    moving_avg.fit(city_data['train'], city_data['train']['AQI'])\n",
    "    val_pred_ma = moving_avg.predict(city_data['val'])\n",
    "    test_pred_ma = moving_avg.predict(city_data['test'])\n",
    "\n",
    "     # Calculate feature importance for moving average\n",
    "    # For moving average, each lag has equal importance (1/window_size)\n",
    "    ma_importance = {\n",
    "        f'AQI_lag_{i}': 1.0/moving_avg.window_size \n",
    "        for i in range(1, moving_avg.window_size + 1)\n",
    "    }\n",
    "    # Add zeros for lags beyond window size\n",
    "    for i in range(moving_avg.window_size + 1, 8):\n",
    "        ma_importance[f'AQI_lag_{i}'] = 0.0\n",
    "    \n",
    "    \n",
    "    # Calculate metrics\n",
    "    persistence_val_metrics = calculate_metrics(city_data['val']['AQI'].values, val_pred_persistence, 'val_')\n",
    "    persistence_test_metrics = calculate_metrics(city_data['test']['AQI'].values, test_pred_persistence, 'test_')\n",
    "    \n",
    "    ma_val_metrics = calculate_metrics(city_data['val']['AQI'].values, val_pred_ma, 'val_')\n",
    "    ma_test_metrics = calculate_metrics(city_data['test']['AQI'].values, test_pred_ma, 'test_')\n",
    "\n",
    "    \n",
    "    # Store results\n",
    "    results['persistence'] = {\n",
    "        'validation': persistence_val_metrics,\n",
    "        'test': persistence_test_metrics,\n",
    "        'predictions': {\n",
    "            'val': val_pred_persistence,\n",
    "            'test': test_pred_persistence\n",
    "        },\n",
    "        'model_config': {\n",
    "            'name': 'Persistence',\n",
    "            'parameters': {},\n",
    "            'feature_importance': persistence_importance\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results['moving_average'] = {\n",
    "        'validation': ma_val_metrics,\n",
    "        'test': ma_test_metrics,\n",
    "        'predictions': {\n",
    "            'val': val_pred_ma,\n",
    "            'test': test_pred_ma\n",
    "        },\n",
    "        'model_config': {\n",
    "            'name': 'Moving Average',\n",
    "            'parameters': {'window_size': moving_avg.window_size},\n",
    "            'feature_importance': ma_importance\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Update the ModelResultsManager class to handle ML results\n",
    "class ModelResultsManager:\n",
    "    def __init__(self):\n",
    "        self.base_dir = \"./results\"\n",
    "        self.ml_dir = f\"{self.base_dir}/ml_models\"\n",
    "        self._create_directory_structure()\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        os.makedirs(self.ml_dir, exist_ok=True)\n",
    "        for city in ['Bengaluru', 'Chennai', 'Delhi', 'Hyderabad']:\n",
    "            city_dir = f\"{self.ml_dir}/{city}\"\n",
    "            os.makedirs(city_dir, exist_ok=True)\n",
    "            os.makedirs(f\"{city_dir}/visualizations\", exist_ok=True)\n",
    "    \n",
    "    def save_ml_results(self, city, results):\n",
    "        \"\"\"Save ML model results\"\"\"\n",
    "        city_dir = f\"{self.ml_dir}/{city}\"\n",
    "        \n",
    "        # Save results for each model\n",
    "        for model_name, model_results in results.items():\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            serializable_results = {\n",
    "                'validation': model_results['validation'],\n",
    "                'test': model_results['test'],\n",
    "                'predictions': model_results['predictions'],\n",
    "                'model_config': model_results['model_config']\n",
    "            }\n",
    "            \n",
    "            # Save to file\n",
    "            with open(f\"{city_dir}/{model_name}_results.json\", 'w') as f:\n",
    "                json.dump(serializable_results, f, indent=4)\n",
    "        \n",
    "        # Update metadata\n",
    "        self._update_metadata(city, results)\n",
    "    \n",
    "    def _update_metadata(self, city, results):\n",
    "        \"\"\"Update metadata file with ML model results\"\"\"\n",
    "        metadata_file = f\"{self.base_dir}/metadata.json\"\n",
    "        \n",
    "        # Load existing metadata\n",
    "        if os.path.exists(metadata_file):\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Update ML results\n",
    "        if 'ml_models' not in metadata:\n",
    "            metadata['ml_models'] = {}\n",
    "        \n",
    "        metadata['ml_models'][city] = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'models': list(results.keys()),\n",
    "            'metrics': {\n",
    "                model: {\n",
    "                    'validation': {\n",
    "                        'rmse': results[model]['validation'][f'val_rmse'],\n",
    "                        'mae': results[model]['validation'][f'val_mae'],\n",
    "                        'r2': results[model]['validation'][f'val_r2']\n",
    "                    },\n",
    "                    'test': {\n",
    "                        'rmse': results[model]['test'][f'test_rmse'],\n",
    "                        'mae': results[model]['test'][f'test_mae'],\n",
    "                        'r2': results[model]['test'][f'test_r2']\n",
    "                    }\n",
    "                }\n",
    "                for model in results\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define ModelResultsManager class\n",
    "class ModelResultsManager:\n",
    "    def __init__(self, base_dir='results'):\n",
    "        self.base_dir = base_dir\n",
    "        self._create_directory_structure()\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Create necessary directories for storing results\"\"\"\n",
    "        os.makedirs(f'{self.base_dir}', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/model_configs', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/predictions', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/performance_metrics', exist_ok=True)\n",
    "        os.makedirs(f'{self.base_dir}/plots', exist_ok=True)\n",
    "    \n",
    "    def _convert_to_serializable(self, obj):\n",
    "        \"\"\"Convert numpy arrays and other non-serializable objects to serializable format\"\"\"\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: self._convert_to_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self._convert_to_serializable(item) for item in obj]\n",
    "        elif isinstance(obj, tuple):\n",
    "            return tuple(self._convert_to_serializable(item) for item in obj)\n",
    "        elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8,\n",
    "                            np.uint64, np.uint32, np.uint16, np.uint8)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float64, np.float32, np.float16)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        return obj\n",
    "    \n",
    "    def _update_metadata(self, city_name, model_type, results):\n",
    "        \"\"\"Update metadata file with latest results\"\"\"\n",
    "        metadata_file = f'{self.base_dir}/metadata.json'\n",
    "        \n",
    "        # Load existing metadata or create new\n",
    "        if os.path.exists(metadata_file):\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Update metadata for this city and model type\n",
    "        if city_name not in metadata:\n",
    "            metadata[city_name] = {}\n",
    "        \n",
    "        metadata[city_name][model_type] = {\n",
    "            'last_updated': datetime.now().isoformat(),\n",
    "            'metrics_used': ['rmse', 'mae', 'r2'],\n",
    "            'results': {\n",
    "                'persistence': {\n",
    "                    'validation': results['persistence']['validation'],\n",
    "                    'test': results['persistence']['test']\n",
    "                },\n",
    "                'moving_average': {\n",
    "                    'validation': results['moving_average']['validation'],\n",
    "                    'test': results['moving_average']['test']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    def save_baseline_results(self, city_name, results):\n",
    "        \"\"\"Save baseline model results for a city\"\"\"\n",
    "        # Convert results to serializable format\n",
    "        serializable_results = self._convert_to_serializable(results)\n",
    "        \n",
    "        # Save performance metrics\n",
    "        metrics_file = f'{self.base_dir}/performance_metrics/baseline_{city_name}.json'\n",
    "        with open(metrics_file, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=4)\n",
    "        \n",
    "        # Save predictions\n",
    "        pred_dir = f'{self.base_dir}/predictions/{city_name}'\n",
    "        os.makedirs(pred_dir, exist_ok=True)\n",
    "        \n",
    "        for model_name in ['persistence', 'moving_average']:\n",
    "            pred_data = {\n",
    "                'validation': serializable_results[model_name]['predictions']['val'],\n",
    "                'test': serializable_results[model_name]['predictions']['test']\n",
    "            }\n",
    "            with open(f'{pred_dir}/{model_name}_predictions.json', 'w') as f:\n",
    "                json.dump(pred_data, f, indent=4)\n",
    "        \n",
    "        # Update metadata\n",
    "        self._update_metadata(city_name, 'baseline', serializable_results)\n",
    "    \n",
    "    def save_plots(self, city_name, fig, plot_name):\n",
    "        \"\"\"Save plots for a city\"\"\"\n",
    "        # Create directory for city plots if it doesn't exist\n",
    "        plot_dir = f'{self.base_dir}/plots/{city_name}'\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_path = f'{plot_dir}/{plot_name}.png'\n",
    "        fig.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    def load_baseline_results(self, city_name):\n",
    "        \"\"\"Load baseline model results for a city\"\"\"\n",
    "        metrics_file = f'{self.base_dir}/performance_metrics/baseline_{city_name}.json'\n",
    "        if not os.path.exists(metrics_file):\n",
    "            raise FileNotFoundError(f\"No results found for {city_name}\")\n",
    "        \n",
    "        with open(metrics_file, 'r') as f:\n",
    "            return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline models for bengaluru\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 17.738\n",
      "val_mae: 12.563\n",
      "val_r2: 0.512\n",
      "val_rmse_ci: (15.407, 20.362)\n",
      "val_mae_ci: (11.152, 14.210)\n",
      "val_r2_ci: (0.361, 0.623)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 11.324\n",
      "test_mae: 7.906\n",
      "test_r2: 0.667\n",
      "test_rmse_ci: (9.858, 12.781)\n",
      "test_mae_ci: (7.142, 8.675)\n",
      "test_r2_ci: (0.562, 0.746)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 21.624\n",
      "val_mae: 16.289\n",
      "val_r2: 0.275\n",
      "val_rmse_ci: (19.245, 23.987)\n",
      "val_mae_ci: (14.651, 17.989)\n",
      "val_r2_ci: (0.127, 0.398)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 13.973\n",
      "test_mae: 9.713\n",
      "test_r2: 0.492\n",
      "test_rmse_ci: (12.076, 16.079)\n",
      "test_mae_ci: (8.797, 10.840)\n",
      "test_r2_ci: (0.390, 0.577)\n",
      "\n",
      "Results and plots saved for bengaluru\n",
      "\n",
      "Evaluating baseline models for chennai\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 36.885\n",
      "val_mae: 23.734\n",
      "val_r2: 0.269\n",
      "val_rmse_ci: (31.567, 42.050)\n",
      "val_mae_ci: (20.549, 27.087)\n",
      "val_r2_ci: (0.054, 0.437)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 27.243\n",
      "test_mae: 16.415\n",
      "test_r2: 0.426\n",
      "test_rmse_ci: (22.751, 31.857)\n",
      "test_mae_ci: (14.265, 18.599)\n",
      "test_r2_ci: (0.148, 0.601)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 43.660\n",
      "val_mae: 31.500\n",
      "val_r2: -0.025\n",
      "val_rmse_ci: (38.360, 48.908)\n",
      "val_mae_ci: (28.249, 35.215)\n",
      "val_r2_ci: (-0.170, 0.108)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 32.677\n",
      "test_mae: 19.959\n",
      "test_r2: 0.174\n",
      "test_rmse_ci: (26.853, 38.653)\n",
      "test_mae_ci: (17.551, 22.644)\n",
      "test_r2_ci: (-0.122, 0.381)\n",
      "\n",
      "Results and plots saved for chennai\n",
      "\n",
      "Evaluating baseline models for delhi\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 53.260\n",
      "val_mae: 39.077\n",
      "val_r2: 0.792\n",
      "val_rmse_ci: (47.266, 59.363)\n",
      "val_mae_ci: (35.010, 43.128)\n",
      "val_r2_ci: (0.734, 0.840)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 45.105\n",
      "test_mae: 31.559\n",
      "test_r2: 0.843\n",
      "test_rmse_ci: (40.457, 49.434)\n",
      "test_mae_ci: (28.448, 34.720)\n",
      "test_r2_ci: (0.810, 0.871)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 65.436\n",
      "val_mae: 50.511\n",
      "val_r2: 0.686\n",
      "val_rmse_ci: (58.885, 71.322)\n",
      "val_mae_ci: (45.728, 55.419)\n",
      "val_r2_ci: (0.613, 0.748)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 66.572\n",
      "test_mae: 46.647\n",
      "test_r2: 0.658\n",
      "test_rmse_ci: (60.357, 72.940)\n",
      "test_mae_ci: (41.963, 51.622)\n",
      "test_r2_ci: (0.575, 0.717)\n",
      "\n",
      "Results and plots saved for delhi\n",
      "\n",
      "Evaluating baseline models for hyderabad\n",
      "\n",
      "Persistence Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 14.052\n",
      "val_mae: 10.559\n",
      "val_r2: 0.719\n",
      "val_rmse_ci: (12.276, 15.951)\n",
      "val_mae_ci: (9.512, 11.698)\n",
      "val_r2_ci: (0.625, 0.792)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 14.221\n",
      "test_mae: 9.861\n",
      "test_r2: 0.840\n",
      "test_rmse_ci: (12.486, 15.996)\n",
      "test_mae_ci: (8.832, 10.859)\n",
      "test_r2_ci: (0.794, 0.877)\n",
      "\n",
      "Moving Average Model:\n",
      "Validation Metrics:\n",
      "val_rmse: 21.699\n",
      "val_mae: 16.349\n",
      "val_r2: 0.331\n",
      "val_rmse_ci: (19.603, 24.029)\n",
      "val_mae_ci: (14.789, 18.100)\n",
      "val_r2_ci: (0.183, 0.446)\n",
      "\n",
      "Test Metrics:\n",
      "test_rmse: 21.981\n",
      "test_mae: 16.111\n",
      "test_r2: 0.619\n",
      "test_rmse_ci: (20.066, 23.956)\n",
      "test_mae_ci: (14.700, 17.563)\n",
      "test_r2_ci: (0.539, 0.684)\n",
      "\n",
      "Results and plots saved for hyderabad\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Run evaluation and save results\n",
    "results_manager = ModelResultsManager(\"./results/baseline\")\n",
    "baseline_results = {}\n",
    "\n",
    "for city in cities:\n",
    "    print(f\"\\nEvaluating baseline models for {city}\")\n",
    "    baseline_results[city] = evaluate_baseline_models(city_data[city], city)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nPersistence Model:\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print_metrics(baseline_results[city]['persistence']['validation'])\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print_metrics(baseline_results[city]['persistence']['test'])\n",
    "    \n",
    "    print(\"\\nMoving Average Model:\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print_metrics(baseline_results[city]['moving_average']['validation'])\n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print_metrics(baseline_results[city]['moving_average']['test'])\n",
    "    \n",
    "    # Save results\n",
    "    results_manager.save_baseline_results(city, baseline_results[city])\n",
    "    \n",
    "    # Generate and save plots\n",
    "    fig = plot_metrics_comparison(city, baseline_results[city])\n",
    "    results_manager.save_plots(city, fig, 'metrics_comparison')\n",
    "    \n",
    "    fig = plot_predictions(city, baseline_results[city], 'test')\n",
    "    results_manager.save_plots(city, fig, 'test_predictions')\n",
    "\n",
    "    fig = plot_feature_importance(city, baseline_results[city])\n",
    "    results_manager.save_plots(city, fig, 'feature_importances')\n",
    "    \n",
    "    print(f\"\\nResults and plots saved for {city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelEvaluator:\n",
    "    def __init__(self, city_data, city_name):\n",
    "        self.city_data = city_data\n",
    "        self.city_name = city_name\n",
    "        self.scaler = StandardScaler()\n",
    "        self.results = {}\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare data for ML models\"\"\"\n",
    "        # Get numeric columns only (excluding date, city, and AQI)\n",
    "        numeric_cols = self.city_data['train'].select_dtypes(include=[np.number]).columns\n",
    "        numeric_cols = [col for col in numeric_cols if col not in ['AQI']]\n",
    "        \n",
    "        # Separate features and target\n",
    "        X_train = self.city_data['train'][numeric_cols]\n",
    "        y_train = self.city_data['train']['AQI']\n",
    "        \n",
    "        X_val = self.city_data['val'][numeric_cols]\n",
    "        y_val = self.city_data['val']['AQI']\n",
    "        \n",
    "        X_test = self.city_data['test'][numeric_cols]\n",
    "        y_test = self.city_data['test']['AQI']\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.scaler.transform(X_val)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        return {\n",
    "            'train': {'X': X_train_scaled, 'y': y_train},\n",
    "            'val': {'X': X_val_scaled, 'y': y_val},\n",
    "            'test': {'X': X_test_scaled, 'y': y_test},\n",
    "            'feature_names': numeric_cols  # Removed .tolist() since it's already a list\n",
    "        }\n",
    "    \n",
    "    def calculate_confidence_intervals(self, y_true, y_pred, metric_func, n_bootstrap=1000):\n",
    "        \"\"\"Calculate 95% confidence intervals using bootstrap sampling\"\"\"\n",
    "        scores = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "            score = metric_func(y_true[indices], y_pred[indices])\n",
    "            scores.append(score)\n",
    "        return np.percentile(scores, [2.5, 97.5])\n",
    "    \n",
    "    def evaluate_model(self, model, model_name, param_grid=None):\n",
    "        \"\"\"Evaluate a single ML model\"\"\"\n",
    "        data = self.prepare_data()\n",
    "        \n",
    "        if param_grid:\n",
    "            grid_search = GridSearchCV(\n",
    "                model, param_grid, cv=5, scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1, verbose=1\n",
    "            )\n",
    "            grid_search.fit(data['train']['X'], data['train']['y'])\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "        else:\n",
    "            best_model = model\n",
    "            best_model.fit(data['train']['X'], data['train']['y'])\n",
    "            best_params = {}\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = {\n",
    "            'val': best_model.predict(data['val']['X']),\n",
    "            'test': best_model.predict(data['test']['X'])\n",
    "        }\n",
    "        \n",
    "        # Calculate metrics with confidence intervals\n",
    "        metrics = {}\n",
    "        for split in ['val', 'test']:\n",
    "            y_true = data[split]['y']\n",
    "            y_pred = predictions[split]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            \n",
    "            # Calculate confidence intervals\n",
    "            rmse_ci = self.calculate_confidence_intervals(\n",
    "                y_true, y_pred, lambda yt, yp: np.sqrt(mean_squared_error(yt, yp))\n",
    "            )\n",
    "            mae_ci = self.calculate_confidence_intervals(\n",
    "                y_true, y_pred, mean_absolute_error\n",
    "            )\n",
    "            r2_ci = self.calculate_confidence_intervals(\n",
    "                y_true, y_pred, r2_score\n",
    "            )\n",
    "            \n",
    "            metrics[split] = {\n",
    "                f'{split}_rmse': rmse,\n",
    "                f'{split}_mae': mae,\n",
    "                f'{split}_r2': r2,\n",
    "                f'{split}_rmse_ci': rmse_ci.tolist(),\n",
    "                f'{split}_mae_ci': mae_ci.tolist(),\n",
    "                f'{split}_r2_ci': r2_ci.tolist()\n",
    "            }\n",
    "        \n",
    "        # Get feature importance if available\n",
    "        feature_importance = None\n",
    "        if hasattr(best_model, 'feature_importances_'):\n",
    "            feature_importance = dict(zip(data['feature_names'], \n",
    "                                       best_model.feature_importances_))\n",
    "        elif hasattr(best_model, 'coef_'):\n",
    "            feature_importance = dict(zip(data['feature_names'], \n",
    "                                       best_model.coef_))\n",
    "        elif isinstance(best_model, SVR) and best_model.kernel == 'rbf':\n",
    "            # For SVR with RBF kernel, use permutation importance\n",
    "            perm_importance = permutation_importance(\n",
    "                best_model, \n",
    "                data['test']['X'], \n",
    "                data['test']['y'],\n",
    "                n_repeats=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            feature_importance = dict(zip(data['feature_names'], perm_importance.importances_mean))\n",
    "        \n",
    "        # Store results in baseline-compatible format\n",
    "        self.results[model_name] = {\n",
    "            'val': metrics['val'],\n",
    "            'test': metrics['test'],\n",
    "            'predictions': {\n",
    "                'val': predictions['val'].tolist(),\n",
    "                'test': predictions['test'].tolist()\n",
    "            },\n",
    "            'model_config': {\n",
    "                'name': model_name,\n",
    "                'parameters': best_params,\n",
    "                'feature_importance': feature_importance\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return self.results[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_ml_models(city_data, city_name):\n",
    "    \"\"\"Evaluate all ML models for a given city\"\"\"\n",
    "    evaluator = MLModelEvaluator(city_data, city_name)\n",
    "    \n",
    "    # Define models and their parameter grids\n",
    "    models = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'param_grid': None\n",
    "        },\n",
    "        'ridge': {\n",
    "            'model': Ridge(),\n",
    "            'param_grid': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'param_grid': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            }\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': RandomForestRegressor(random_state=42),\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5]\n",
    "            }\n",
    "        },\n",
    "        'gradient_boosting': {\n",
    "            'model': GradientBoostingRegressor(random_state=42),\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 5]\n",
    "            }\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'model': xgb.XGBRegressor(random_state=42),\n",
    "            'param_grid': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 5]\n",
    "            }\n",
    "        },\n",
    "        'svr': {\n",
    "            'model': SVR(),\n",
    "            'param_grid': {\n",
    "                'kernel': ['linear', 'rbf'],\n",
    "                'C': [0.1, 1.0, 10.0],\n",
    "                'epsilon': [0.1, 0.2]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model_name, model_config in models.items():\n",
    "        print(f\"\\nEvaluating {model_name} for {city_name}...\")\n",
    "        evaluator.evaluate_model(\n",
    "            model_config['model'],\n",
    "            model_name,\n",
    "            model_config['param_grid']\n",
    "        )\n",
    "        \n",
    "    \n",
    "    return evaluator.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, (np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.int32, np.int64)):\n",
    "            return int(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "def save_ml_results(city_name, results):\n",
    "    \"\"\"Save ML model results\"\"\"\n",
    "    # Create results directory if it doesn't exist\n",
    "    results_dir = f\"./results/ml_models/{city_name}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results for each model\n",
    "    for model_name, model_results in results.items():\n",
    "        # Save to file using the custom encoder\n",
    "        with open(f\"{results_dir}/{model_name}_results.json\", 'w') as f:\n",
    "            json.dump(model_results, f, indent=4, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(city, results):\n",
    "    \"\"\"Plot comparison of metrics for different models\"\"\"\n",
    "    # Define metrics and splits\n",
    "    metrics = ['rmse', 'mae', 'r2']\n",
    "    splits = ['val', 'test']\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = list(results.keys())\n",
    "    n_models = len(models)\n",
    "    n_metrics = len(metrics)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, n_metrics, figsize=(6*n_metrics, 6))\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Collect values and confidence intervals\n",
    "        values = {split: [] for split in splits}\n",
    "        cis = {split: [] for split in splits}\n",
    "        \n",
    "        for model in models:\n",
    "            for split in splits:\n",
    "                metric_key = f'{split}_{metric}'\n",
    "                ci_key = f'{split}_{metric}_ci'\n",
    "                \n",
    "                if metric_key in results[model][split]:\n",
    "                    values[split].append(results[model][split][metric_key])\n",
    "                    # Convert CI to error bar format (half-width)\n",
    "                    ci = results[model][split][ci_key]\n",
    "                    if isinstance(ci, (list, np.ndarray)) and len(ci) == 2:\n",
    "                        ci_half_width = (ci[1] - ci[0]) / 2\n",
    "                        cis[split].append(ci_half_width)\n",
    "                    else:\n",
    "                        cis[split].append(0)  # No error bar if CI is invalid\n",
    "                else:\n",
    "                    values[split].append(None)\n",
    "                    cis[split].append(0)\n",
    "        \n",
    "        # Plot bars\n",
    "        x = np.arange(n_models)\n",
    "        width = 0.35\n",
    "        \n",
    "        for j, split in enumerate(splits):\n",
    "            valid_values = [v for v in values[split] if v is not None]\n",
    "            if valid_values:\n",
    "                ax.bar(x + j*width, values[split], width, label=split.capitalize())\n",
    "                \n",
    "                # Add error bars\n",
    "                for k, (val, ci) in enumerate(zip(values[split], cis[split])):\n",
    "                    if val is not None:\n",
    "                        ax.errorbar(x[k] + j*width, val, yerr=ci, \n",
    "                                  fmt='none', color='black', capsize=5)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Models')\n",
    "        ax.set_ylabel(metric.upper())\n",
    "        ax.set_title(f'{metric.upper()} Comparison')\n",
    "        ax.set_xticks(x + width/2)\n",
    "        ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_predictions(city, results, data_split, actual_values):\n",
    "    \"\"\"Plot actual vs predicted values for all models\"\"\"\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Plot actual values\n",
    "    ax.plot(actual_values, label='Actual', color='black', alpha=0.7)\n",
    "    \n",
    "    # Plot predictions for each model\n",
    "    for model_name, model_results in results.items():\n",
    "        predictions = model_results['predictions'][data_split]\n",
    "        ax.plot(predictions, label=model_name, alpha=0.7)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('AQI')\n",
    "    ax.set_title(f'Actual vs Predicted AQI - {data_split.capitalize()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_feature_importance(city, results):\n",
    "    \"\"\"Plot feature importance for models that support it\"\"\"\n",
    "    # Get models with feature importance\n",
    "    models_with_importance = {\n",
    "        name: results[name]['model_config']['feature_importance']\n",
    "        for name in results\n",
    "        if results[name]['model_config']['feature_importance'] is not None\n",
    "    }\n",
    "    \n",
    "    if not models_with_importance:\n",
    "        print(\"No models with feature importance found\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    n_models = len(models_with_importance)\n",
    "    fig, axes = plt.subplots(n_models, 1, figsize=(15, 5*n_models))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (model_name, importance) in enumerate(models_with_importance.items()):\n",
    "        print(f\"\\nDebugging {model_name}:\")\n",
    "        print(\"Feature importance structure:\", importance)\n",
    "        \n",
    "        # Handle different formats of feature importance\n",
    "        if isinstance(importance, dict):\n",
    "            # For models with dictionary format (most models)\n",
    "            sorted_features = sorted(importance.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "            features, values = zip(*sorted_features)\n",
    "            \n",
    "            # Convert values to float if they're arrays\n",
    "            try:\n",
    "                values = [float(v) if hasattr(v, '__len__') else v for v in values]\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting values: {e}\")\n",
    "                print(\"Original values:\", values)\n",
    "                # Try alternative conversion\n",
    "                values = [float(v[0]) if hasattr(v, '__len__') else float(v) for v in values]\n",
    "        else:\n",
    "            # For models with array format (SVR with linear kernel)\n",
    "            features = ['PM2.5']  # Assuming PM2.5 is the target\n",
    "            values = [float(importance[0])]  # Take the first value from the array\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = axes[idx].barh(features, values)\n",
    "        \n",
    "        # Color bars based on sign\n",
    "        for bar in bars:\n",
    "            if bar.get_width() < 0:\n",
    "                bar.set_color('red')\n",
    "            else:\n",
    "                bar.set_color('blue')\n",
    "        \n",
    "        # Add vertical line at x=0\n",
    "        axes[idx].axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        axes[idx].set_title(f'Feature Importance - {model_name.replace(\"_\", \" \").title()}')\n",
    "        axes[idx].set_xlabel('Importance')\n",
    "        axes[idx].set_ylabel('Features')\n",
    "    \n",
    "    plt.suptitle(f'Feature Importance Analysis - {city.title()}', y=1.05)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def save_ml_visualizations(city, results, city_data):\n",
    "    \"\"\"Save all visualizations for ML models\"\"\"\n",
    "    # Create visualization directory\n",
    "    viz_dir = f\"./notebooks/results/ml_models/{city}/visualizations\"\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate and save plots\n",
    "    fig = plot_metrics_comparison(city, results)\n",
    "    fig.savefig(f\"{viz_dir}/metrics_comparison.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = plot_feature_importance(city, results)\n",
    "    fig.savefig(f\"{viz_dir}/feature_importance.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    # Plot predictions for each split\n",
    "    for split in ['val', 'test']:\n",
    "        # Get actual values from the data\n",
    "        actual_values = city_data[split]['AQI'].values\n",
    "        fig = plot_predictions(city, results, split, actual_values)\n",
    "        fig.savefig(f\"{viz_dir}/predictions_{split}.png\", bbox_inches='tight', dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First, let's load the preprocessed data for each city\n",
    "def load_city_data(city_name):\n",
    "    \"\"\"Load preprocessed data for a specific city\"\"\"\n",
    "    data_dir = \"../data/processed\"\n",
    "    city_data = {}\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        file_path = f\"{data_dir}/{city_name}/{split}.csv\"\n",
    "        # print(file_path)\n",
    "        if os.path.exists(file_path):\n",
    "            city_data[split] = pd.read_csv(file_path)\n",
    "            city_data[split]['date'] = pd.to_datetime(city_data[split]['Date'])\n",
    "    \n",
    "    return city_data\n",
    "\n",
    "def run_ml_analysis():\n",
    "    \"\"\"Run ML analysis for all cities\"\"\"\n",
    "    cities = ['bengaluru', 'chennai', 'delhi', 'hyderabad']\n",
    "    \n",
    "    for city in cities:\n",
    "        print(f\"\\nProcessing {city}...\")\n",
    "        \n",
    "        # Load city data\n",
    "        city_data = load_city_data(city)\n",
    "        if not city_data:\n",
    "            print(f\"No data found for {city}\")\n",
    "            continue\n",
    "        \n",
    "        # Evaluate all ML models\n",
    "        print(\"Evaluating ML models...\")\n",
    "        ml_results = evaluate_all_ml_models(city_data, city)\n",
    "        \n",
    "        # Save results\n",
    "        print(\"Saving results...\")\n",
    "        save_ml_results(city, ml_results)\n",
    "        \n",
    "        # Generate and save visualizations\n",
    "        print(\"Generating visualizations...\")\n",
    "        save_ml_visualizations(city, ml_results, city_data)\n",
    "        \n",
    "        # Print summary metrics\n",
    "        print(\"\\nModel Performance Summary:\")\n",
    "        for model_name, results in ml_results.items():\n",
    "            print(f\"\\n{model_name.replace('_', ' ').title()}:\")\n",
    "            for split in ['val', 'test']:\n",
    "                print(f\"{split.title()} Set:\")\n",
    "                print(f\"  RMSE: {results[split][f'{split}_rmse']:.2f}\")\n",
    "                print(f\"  MAE: {results[split][f'{split}_mae']:.2f}\")\n",
    "                print(f\"  R: {results[split][f'{split}_r2']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Update the ModelResultsManager class to handle ML results\n",
    "class ModelResultsManager:\n",
    "    def __init__(self):\n",
    "        self.base_dir = \"./results\"\n",
    "        self.ml_dir = f\"{self.base_dir}/ml_models\"\n",
    "        self._create_directory_structure()\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        os.makedirs(self.ml_dir, exist_ok=True)\n",
    "        for city in ['Bengaluru', 'Chennai', 'Delhi', 'Hyderabad']:\n",
    "            city_dir = f\"{self.ml_dir}/{city}\"\n",
    "            os.makedirs(city_dir, exist_ok=True)\n",
    "            os.makedirs(f\"{city_dir}/visualizations\", exist_ok=True)\n",
    "    \n",
    "    def save_ml_results(self, city, results):\n",
    "        \"\"\"Save ML model results\"\"\"\n",
    "        city_dir = f\"{self.ml_dir}/{city}\"\n",
    "        \n",
    "        # Save results for each model\n",
    "        for model_name, model_results in results.items():\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            serializable_results = {\n",
    "                'validation': model_results['validation'],\n",
    "                'test': model_results['test'],\n",
    "                'predictions': model_results['predictions'],\n",
    "                'model_config': model_results['model_config']\n",
    "            }\n",
    "            \n",
    "            # Save to file\n",
    "            with open(f\"{city_dir}/{model_name}_results.json\", 'w') as f:\n",
    "                json.dump(serializable_results, f, indent=4)\n",
    "        \n",
    "        # Update metadata\n",
    "        self._update_metadata(city, results)\n",
    "    \n",
    "    def _update_metadata(self, city, results):\n",
    "        \"\"\"Update metadata file with ML model results\"\"\"\n",
    "        metadata_file = f\"{self.base_dir}/metadata.json\"\n",
    "        \n",
    "        # Load existing metadata\n",
    "        if os.path.exists(metadata_file):\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        else:\n",
    "            metadata = {}\n",
    "        \n",
    "        # Update ML results\n",
    "        if 'ml_models' not in metadata:\n",
    "            metadata['ml_models'] = {}\n",
    "        \n",
    "        metadata['ml_models'][city] = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'models': list(results.keys()),\n",
    "            'metrics': {\n",
    "                model: {\n",
    "                    'validation': {\n",
    "                        'rmse': results[model]['validation'][f'val_rmse'],\n",
    "                        'mae': results[model]['validation'][f'val_mae'],\n",
    "                        'r2': results[model]['validation'][f'val_r2']\n",
    "                    },\n",
    "                    'test': {\n",
    "                        'rmse': results[model]['test'][f'test_rmse'],\n",
    "                        'mae': results[model]['test'][f'test_mae'],\n",
    "                        'r2': results[model]['test'][f'test_r2']\n",
    "                    }\n",
    "                }\n",
    "                for model in results\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bengaluru...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for bengaluru...\n",
      "\n",
      "Evaluating ridge for bengaluru...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for bengaluru...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for bengaluru...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for bengaluru...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for bengaluru...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for bengaluru...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(11.245920919896736), 'PM10': np.float64(9.566417657086019), 'NO': np.float64(4.182867582259376), 'NO2': np.float64(-0.1882131403400237), 'NOx': np.float64(0.8313367302709116), 'NH3': np.float64(0.25105934966946597), 'CO': np.float64(18.874496747145173), 'SO2': np.float64(-1.0205482010450877), 'O3': np.float64(5.325602976437243), 'Benzene': np.float64(-1.2372865004271292), 'Toluene': np.float64(-1.0039737742120465), 'tempmax': np.float64(5.329543953135186), 'tempmin': np.float64(-25.821330202307244), 'temp': np.float64(-11.510782600149415), 'feelslikemax': np.float64(-4.420931500966147), 'feelslikemin': np.float64(21.10045859218831), 'feelslike': np.float64(18.689411295744826), 'dew': np.float64(-1.1908120808982834), 'humidity': np.float64(1.3301137510535932), 'precip': np.float64(-1.2028956861488305), 'precipprob': np.float64(0.10126988653505427), 'precipcover': np.float64(-1.5147729570919861), 'windgust': np.float64(0.23267990027534174), 'windspeed': np.float64(-0.10253459948944359), 'winddir': np.float64(2.0208320930356445), 'sealevelpressure': np.float64(-0.4965400671686027), 'cloudcover': np.float64(-2.798712420039299), 'visibility': np.float64(-4.0226078643417775), 'solarradiation': np.float64(56.77032181647565), 'solarenergy': np.float64(-55.81159887742595), 'uvindex': np.float64(-6.259851817306005), 'moonphase': np.float64(-1.393517814176045), 'StratoO3': np.float64(-0.4453119766989894), 'year': np.float64(-8.131572391647472), 'month': np.float64(-3.8133215049788785), 'day': np.float64(-0.38675502970388714), 'dayofweek': np.float64(0.19513054833158683)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(11.224240046021166), 'PM10': np.float64(9.587258718052919), 'NO': np.float64(4.167940144801228), 'NO2': np.float64(-0.17297637438855262), 'NOx': np.float64(0.8200450882211382), 'NH3': np.float64(0.25210675924106646), 'CO': np.float64(18.87432404745443), 'SO2': np.float64(-1.0159872428728705), 'O3': np.float64(5.344527593223784), 'Benzene': np.float64(-1.22801079150097), 'Toluene': np.float64(-0.9984485085183227), 'tempmax': np.float64(5.241930159260097), 'tempmin': np.float64(-20.943653104810387), 'temp': np.float64(-11.270627841686455), 'feelslikemax': np.float64(-4.318956829727022), 'feelslikemin': np.float64(16.183084802592933), 'feelslike': np.float64(18.40955332819325), 'dew': np.float64(-1.111359671027661), 'humidity': np.float64(1.2558157715396616), 'precip': np.float64(-1.2264050231301833), 'precipprob': np.float64(0.09155197483662947), 'precipcover': np.float64(-1.4958591248025006), 'windgust': np.float64(0.2301699334036059), 'windspeed': np.float64(-0.10506774644921102), 'winddir': np.float64(2.0086423065990275), 'sealevelpressure': np.float64(-0.48735236724846787), 'cloudcover': np.float64(-2.7826648089951296), 'visibility': np.float64(-4.01288079754785), 'solarradiation': np.float64(41.12793512578049), 'solarenergy': np.float64(-40.23348040822163), 'uvindex': np.float64(-6.205043651341398), 'moonphase': np.float64(-1.4004732758721277), 'StratoO3': np.float64(-0.4206374627746168), 'year': np.float64(-8.123384457163757), 'month': np.float64(-3.80202318306266), 'day': np.float64(-0.40180980029168806), 'dayofweek': np.float64(0.18852120586091084)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(11.048204853265394), 'PM10': np.float64(9.561705091691477), 'NO': np.float64(3.822708428672832), 'NO2': np.float64(0.0), 'NOx': np.float64(0.8104658602500336), 'NH3': np.float64(0.13144810194667178), 'CO': np.float64(18.823039756478497), 'SO2': np.float64(-0.7653614657321455), 'O3': np.float64(5.401902556840189), 'Benzene': np.float64(-0.8945848874599424), 'Toluene': np.float64(-0.9265396640606861), 'tempmax': np.float64(0.02973295055771159), 'tempmin': np.float64(-5.739224063908986), 'temp': np.float64(-0.0), 'feelslikemax': np.float64(0.0), 'feelslikemin': np.float64(-0.0), 'feelslike': np.float64(7.82341406425427), 'dew': np.float64(-0.0), 'humidity': np.float64(-0.0), 'precip': np.float64(-1.209039688783386), 'precipprob': np.float64(-0.0), 'precipcover': np.float64(-1.324744992599223), 'windgust': np.float64(0.07859610540780253), 'windspeed': np.float64(-0.009400408491223094), 'winddir': np.float64(1.7260871807670461), 'sealevelpressure': np.float64(-0.05738480643135102), 'cloudcover': np.float64(-2.2830130001202624), 'visibility': np.float64(-3.838254215713421), 'solarradiation': np.float64(0.0), 'solarenergy': np.float64(0.0), 'uvindex': np.float64(-4.957754339385542), 'moonphase': np.float64(-1.3796270405005109), 'StratoO3': np.float64(-0.1790451838090263), 'year': np.float64(-7.840255875584422), 'month': np.float64(-3.5976024627500367), 'day': np.float64(-0.3464918111662472), 'dayofweek': np.float64(0.07043948166628833)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.1795964367637923), 'PM10': np.float64(0.10151086305389258), 'NO': np.float64(0.028733837879204135), 'NO2': np.float64(0.0197442489988365), 'NOx': np.float64(0.012558029327904674), 'NH3': np.float64(0.010894924195622506), 'CO': np.float64(0.3159788878605108), 'SO2': np.float64(0.016961665804077476), 'O3': np.float64(0.043144582049603024), 'Benzene': np.float64(0.014588655567576367), 'Toluene': np.float64(0.018878328984243464), 'tempmax': np.float64(0.008139102494614227), 'tempmin': np.float64(0.007320053092280505), 'temp': np.float64(0.010463444991233884), 'feelslikemax': np.float64(0.016942287878533052), 'feelslikemin': np.float64(0.007876184714007672), 'feelslike': np.float64(0.00774903209658883), 'dew': np.float64(0.009207452953790713), 'humidity': np.float64(0.011505753258452038), 'precip': np.float64(0.01242934313225621), 'precipprob': np.float64(0.00026654545887510906), 'precipcover': np.float64(0.004418122987655653), 'windgust': np.float64(0.011733105835405455), 'windspeed': np.float64(0.010161325129404679), 'winddir': np.float64(0.013662145362190299), 'sealevelpressure': np.float64(0.010762519943519957), 'cloudcover': np.float64(0.011718124806795904), 'visibility': np.float64(0.014126861394290528), 'solarradiation': np.float64(0.010496180599585127), 'solarenergy': np.float64(0.006983434078516632), 'uvindex': np.float64(0.004001973748525141), 'moonphase': np.float64(0.009968194343131443), 'StratoO3': np.float64(0.01040684877560685), 'year': np.float64(0.003023066476579673), 'month': np.float64(0.0058451535425349125), 'day': np.float64(0.013238605050886145), 'dayofweek': np.float64(0.004964677369475481)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.2429367155132682), 'PM10': np.float64(0.13560842221451902), 'NO': np.float64(0.005218114888423182), 'NO2': np.float64(0.002693289810688676), 'NOx': np.float64(0.011205406460133023), 'NH3': np.float64(0.00028130579206876103), 'CO': np.float64(0.46926310751184747), 'SO2': np.float64(0.0002620802106124817), 'O3': np.float64(0.050386317342087136), 'Benzene': np.float64(0.002228393749378864), 'Toluene': np.float64(0.0051477485853908805), 'tempmax': np.float64(0.0004117541623148077), 'tempmin': np.float64(0.004598548491043586), 'temp': np.float64(0.004243551023794628), 'feelslikemax': np.float64(0.003557829908498916), 'feelslikemin': np.float64(0.0036260232227527146), 'feelslike': np.float64(0.0002970814074107172), 'dew': np.float64(9.555808766874876e-05), 'humidity': np.float64(0.00475672026432852), 'precip': np.float64(0.013889523307078069), 'precipprob': np.float64(0.0), 'precipcover': np.float64(0.00010971134267121769), 'windgust': np.float64(0.00042722997796184513), 'windspeed': np.float64(0.0), 'winddir': np.float64(0.0013678020162756373), 'sealevelpressure': np.float64(0.0034784302073422365), 'cloudcover': np.float64(0.010950147209379221), 'visibility': np.float64(0.0011339901491361597), 'solarradiation': np.float64(0.0030377500562194775), 'solarenergy': np.float64(0.0006864337861620276), 'uvindex': np.float64(0.0025162636252865065), 'moonphase': np.float64(0.0005383119010262445), 'StratoO3': np.float64(0.0033604244019673508), 'year': np.float64(0.009547871124758814), 'month': np.float64(0.0007178999229018352), 'day': np.float64(0.0013227440216865098), 'dayofweek': np.float64(9.749830391669095e-05)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.11941352), 'PM10': np.float32(0.082166255), 'NO': np.float32(0.019270467), 'NO2': np.float32(0.011602511), 'NOx': np.float32(0.022988275), 'NH3': np.float32(0.0), 'CO': np.float32(0.14970744), 'SO2': np.float32(0.028221734), 'O3': np.float32(0.049640574), 'Benzene': np.float32(0.0133533245), 'Toluene': np.float32(0.024033267), 'tempmax': np.float32(0.03147633), 'tempmin': np.float32(0.026971517), 'temp': np.float32(0.029543744), 'feelslikemax': np.float32(0.028573222), 'feelslikemin': np.float32(0.0), 'feelslike': np.float32(0.0), 'dew': np.float32(0.0), 'humidity': np.float32(0.02796469), 'precip': np.float32(0.046915654), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.0), 'windgust': np.float32(0.027734393), 'windspeed': np.float32(0.0), 'winddir': np.float32(0.026304126), 'sealevelpressure': np.float32(0.022943875), 'cloudcover': np.float32(0.015112837), 'visibility': np.float32(0.0), 'solarradiation': np.float32(0.022828322), 'solarenergy': np.float32(0.030641247), 'uvindex': np.float32(0.0), 'moonphase': np.float32(0.018040601), 'StratoO3': np.float32(0.02164169), 'year': np.float32(0.055682596), 'month': np.float32(0.029204497), 'day': np.float32(0.01802322), 'dayofweek': np.float32(0.0)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([11.98115328, 11.12942269,  3.36670415, -1.7433511 ,  2.73780414,\n",
      "        0.05664214, 27.90643549,  0.34997321,  6.04115677, -2.20355663,\n",
      "       -3.09542302,  3.40040803, -2.16571652,  1.29758041, -1.84577255,\n",
      "       -1.31959165,  2.86071619, -1.7465676 ,  2.08185781, -0.58459915,\n",
      "       -0.66527457,  0.14969718, -1.12124056, -0.09659788,  2.29083037,\n",
      "        1.02557599,  0.04701832, -2.11689115,  0.14987604, -0.73613439,\n",
      "       -1.68456739, -0.79478826, -0.25410017, -5.46083276, -1.44638126,\n",
      "       -0.14239319,  1.220232  ])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([11.98115328, 11.12942269,  3.36670415, -1.7433511 ,  2.73780414,\n",
      "        0.05664214, 27.90643549,  0.34997321,  6.04115677, -2.20355663,\n",
      "       -3.09542302,  3.40040803, -2.16571652,  1.29758041, -1.84577255,\n",
      "       -1.31959165,  2.86071619, -1.7465676 ,  2.08185781, -0.58459915,\n",
      "       -0.66527457,  0.14969718, -1.12124056, -0.09659788,  2.29083037,\n",
      "        1.02557599,  0.04701832, -2.11689115,  0.14987604, -0.73613439,\n",
      "       -1.68456739, -0.79478826, -0.25410017, -5.46083276, -1.44638126,\n",
      "       -0.14239319,  1.220232  ]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 21.87\n",
      "  MAE: 18.08\n",
      "  R: 0.26\n",
      "Test Set:\n",
      "  RMSE: 17.28\n",
      "  MAE: 14.92\n",
      "  R: 0.22\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 21.85\n",
      "  MAE: 18.08\n",
      "  R: 0.26\n",
      "Test Set:\n",
      "  RMSE: 17.28\n",
      "  MAE: 14.93\n",
      "  R: 0.22\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 20.97\n",
      "  MAE: 17.31\n",
      "  R: 0.32\n",
      "Test Set:\n",
      "  RMSE: 16.34\n",
      "  MAE: 14.02\n",
      "  R: 0.30\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 14.66\n",
      "  MAE: 11.44\n",
      "  R: 0.67\n",
      "Test Set:\n",
      "  RMSE: 9.32\n",
      "  MAE: 6.89\n",
      "  R: 0.77\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 16.24\n",
      "  MAE: 12.73\n",
      "  R: 0.59\n",
      "Test Set:\n",
      "  RMSE: 10.49\n",
      "  MAE: 8.21\n",
      "  R: 0.71\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 16.29\n",
      "  MAE: 12.68\n",
      "  R: 0.59\n",
      "Test Set:\n",
      "  RMSE: 10.39\n",
      "  MAE: 8.19\n",
      "  R: 0.72\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 18.97\n",
      "  MAE: 15.40\n",
      "  R: 0.45\n",
      "Test Set:\n",
      "  RMSE: 15.03\n",
      "  MAE: 12.94\n",
      "  R: 0.41\n",
      "\n",
      "Processing chennai...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for chennai...\n",
      "\n",
      "Evaluating ridge for chennai...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for chennai...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for chennai...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for chennai...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for chennai...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for chennai...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(29.933770582142767), 'PM10': np.float64(-0.6217993593408835), 'NO': np.float64(-4.976508611551051), 'NO2': np.float64(4.03075197233385), 'NOx': np.float64(2.7140183001003613), 'NH3': np.float64(-3.660214769298119), 'CO': np.float64(18.651572685527928), 'SO2': np.float64(-1.3162404086124886), 'O3': np.float64(2.9618186261702535), 'Benzene': np.float64(-0.951121370459025), 'Toluene': np.float64(-0.7708872378257702), 'tempmax': np.float64(4.097352450175188), 'tempmin': np.float64(8.929993387510697), 'temp': np.float64(-3.978721509034678), 'feelslikemax': np.float64(-0.2779368630020698), 'feelslikemin': np.float64(-5.749726172971464), 'feelslike': np.float64(4.950241264847154), 'dew': np.float64(-13.237916154280697), 'humidity': np.float64(6.88955374724601), 'precip': np.float64(2.9107603077314366), 'precipprob': np.float64(0.7000220274730937), 'precipcover': np.float64(-1.4307122557383414), 'windgust': np.float64(-4.288835904153333), 'windspeed': np.float64(-1.610844499013856), 'winddir': np.float64(0.02622952730840176), 'sealevelpressure': np.float64(-2.75708080262286), 'cloudcover': np.float64(-0.9076519614890831), 'visibility': np.float64(-3.998927358243195), 'solarradiation': np.float64(-5.093994676399146), 'solarenergy': np.float64(6.968451479202701), 'uvindex': np.float64(0.2125984752766046), 'moonphase': np.float64(1.8172745919489184), 'StratoO3': np.float64(-1.8122735457273018), 'year': np.float64(-9.09650504947357), 'month': np.float64(-1.3750618738158007), 'day': np.float64(1.5010590847469674), 'dayofweek': np.float64(1.4574393788182691)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(27.01681031280444), 'PM10': np.float64(0.34831109530636456), 'NO': np.float64(-3.4073104535863936), 'NO2': np.float64(3.599610812129059), 'NOx': np.float64(2.1382339532032604), 'NH3': np.float64(-3.0416615233419426), 'CO': np.float64(16.806246949500316), 'SO2': np.float64(-0.6208519377674613), 'O3': np.float64(3.089994889498139), 'Benzene': np.float64(-0.8310328356841529), 'Toluene': np.float64(-0.4540793936743322), 'tempmax': np.float64(2.2494458799162045), 'tempmin': np.float64(0.34262484266242954), 'temp': np.float64(-1.0202763467616058), 'feelslikemax': np.float64(-0.2584374488006105), 'feelslikemin': np.float64(-1.671888778021593), 'feelslike': np.float64(-2.0008264887148908), 'dew': np.float64(-3.291992134864222), 'humidity': np.float64(-1.1442450745583848), 'precip': np.float64(2.393092741508345), 'precipprob': np.float64(0.4290876739626053), 'precipcover': np.float64(-1.2760774649245075), 'windgust': np.float64(-3.5928110860739984), 'windspeed': np.float64(-1.8040137682289623), 'winddir': np.float64(0.7196686210931538), 'sealevelpressure': np.float64(-2.3446832135413493), 'cloudcover': np.float64(-0.759792037840379), 'visibility': np.float64(-4.450759589067478), 'solarradiation': np.float64(0.6124229202109794), 'solarenergy': np.float64(0.6246197587293034), 'uvindex': np.float64(0.31641419321929753), 'moonphase': np.float64(1.7322770860104826), 'StratoO3': np.float64(-1.6712454542549), 'year': np.float64(-9.528083732616574), 'month': np.float64(-1.7946281794508516), 'day': np.float64(1.2941657617910507), 'dayofweek': np.float64(1.3403835409693685)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(23.780154405540777), 'PM10': np.float64(0.0), 'NO': np.float64(0.0), 'NO2': np.float64(0.0), 'NOx': np.float64(0.0), 'NH3': np.float64(-0.0), 'CO': np.float64(9.31932363133888), 'SO2': np.float64(0.0), 'O3': np.float64(0.0), 'Benzene': np.float64(0.0), 'Toluene': np.float64(0.0), 'tempmax': np.float64(-0.0), 'tempmin': np.float64(-0.0), 'temp': np.float64(-0.0), 'feelslikemax': np.float64(-0.0), 'feelslikemin': np.float64(-0.0), 'feelslike': np.float64(-0.0), 'dew': np.float64(-0.0), 'humidity': np.float64(-0.0), 'precip': np.float64(0.0), 'precipprob': np.float64(-0.0), 'precipcover': np.float64(-0.0), 'windgust': np.float64(-0.0), 'windspeed': np.float64(-0.0), 'winddir': np.float64(-0.0), 'sealevelpressure': np.float64(0.0), 'cloudcover': np.float64(-0.0), 'visibility': np.float64(-0.0), 'solarradiation': np.float64(0.0), 'solarenergy': np.float64(0.0), 'uvindex': np.float64(0.0), 'moonphase': np.float64(0.0), 'StratoO3': np.float64(-0.0), 'year': np.float64(-2.742583480092392), 'month': np.float64(-0.0), 'day': np.float64(0.0), 'dayofweek': np.float64(0.0)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.5299342226372228), 'PM10': np.float64(0.009086492534310986), 'NO': np.float64(0.024649776570465298), 'NO2': np.float64(0.023266414652192795), 'NOx': np.float64(0.015222291450718939), 'NH3': np.float64(0.007434863389260517), 'CO': np.float64(0.20096548887465987), 'SO2': np.float64(0.027067062587238944), 'O3': np.float64(0.019338404773872147), 'Benzene': np.float64(0.0075634755439516945), 'Toluene': np.float64(0.004668795337201178), 'tempmax': np.float64(0.0021934764514775925), 'tempmin': np.float64(0.002677770131909794), 'temp': np.float64(0.0050228602682038355), 'feelslikemax': np.float64(0.004498568929344335), 'feelslikemin': np.float64(0.0025468948543030706), 'feelslike': np.float64(0.0042887197561624095), 'dew': np.float64(0.006308369619470248), 'humidity': np.float64(0.005573865118748859), 'precip': np.float64(0.0028895654859131484), 'precipprob': np.float64(0.00031263680423018373), 'precipcover': np.float64(0.0004364030641574092), 'windgust': np.float64(0.006789667414808332), 'windspeed': np.float64(0.006514595347888067), 'winddir': np.float64(0.0068853933894095455), 'sealevelpressure': np.float64(0.005566031124016637), 'cloudcover': np.float64(0.004454193929054469), 'visibility': np.float64(0.006835196650232913), 'solarradiation': np.float64(0.005080382353947389), 'solarenergy': np.float64(0.004771654692075738), 'uvindex': np.float64(0.0018744472773758764), 'moonphase': np.float64(0.007423159253752869), 'StratoO3': np.float64(0.005431169964436317), 'year': np.float64(0.014361841933834423), 'month': np.float64(0.010668987826663302), 'day': np.float64(0.004767483254816051), 'dayofweek': np.float64(0.002629376752672119)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.650422777622525), 'PM10': np.float64(0.0026581087147852693), 'NO': np.float64(0.00493019505606348), 'NO2': np.float64(0.014502738357490105), 'NOx': np.float64(0.004971893370250939), 'NH3': np.float64(0.003335187942006169), 'CO': np.float64(0.23911909582964003), 'SO2': np.float64(0.013874389278527502), 'O3': np.float64(0.006756529895587742), 'Benzene': np.float64(0.00012651670715070363), 'Toluene': np.float64(0.0), 'tempmax': np.float64(0.0), 'tempmin': np.float64(0.00044575138821572994), 'temp': np.float64(0.0005605683772208236), 'feelslikemax': np.float64(0.0), 'feelslikemin': np.float64(0.0), 'feelslike': np.float64(0.0), 'dew': np.float64(0.0010937997915248699), 'humidity': np.float64(0.004219418637515597), 'precip': np.float64(0.0), 'precipprob': np.float64(0.0), 'precipcover': np.float64(8.840791246946685e-07), 'windgust': np.float64(0.0015151097195788168), 'windspeed': np.float64(2.226519660321663e-05), 'winddir': np.float64(0.0), 'sealevelpressure': np.float64(0.0016880709419521763), 'cloudcover': np.float64(2.266992462608522e-05), 'visibility': np.float64(0.007113256106981272), 'solarradiation': np.float64(0.001724379069003344), 'solarenergy': np.float64(0.0005447123557986777), 'uvindex': np.float64(0.0), 'moonphase': np.float64(0.0011365936807945043), 'StratoO3': np.float64(0.0), 'year': np.float64(0.026401748653492787), 'month': np.float64(0.012255240185790321), 'day': np.float64(2.3329614891650366e-05), 'dayofweek': np.float64(0.0005347695028583498)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.18064237), 'PM10': np.float32(0.0), 'NO': np.float32(0.050495494), 'NO2': np.float32(0.03521545), 'NOx': np.float32(0.040016603), 'NH3': np.float32(0.025738705), 'CO': np.float32(0.16308168), 'SO2': np.float32(0.050974242), 'O3': np.float32(0.019203058), 'Benzene': np.float32(0.0), 'Toluene': np.float32(0.0), 'tempmax': np.float32(0.0), 'tempmin': np.float32(0.027660178), 'temp': np.float32(0.035476398), 'feelslikemax': np.float32(0.0), 'feelslikemin': np.float32(0.0), 'feelslike': np.float32(0.03567246), 'dew': np.float32(0.026863698), 'humidity': np.float32(0.016973268), 'precip': np.float32(0.0), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.0), 'windgust': np.float32(0.024824409), 'windspeed': np.float32(0.0), 'winddir': np.float32(0.0), 'sealevelpressure': np.float32(0.013581458), 'cloudcover': np.float32(0.0), 'visibility': np.float32(0.027869321), 'solarradiation': np.float32(0.037742786), 'solarenergy': np.float32(0.0), 'uvindex': np.float32(0.0), 'moonphase': np.float32(0.0), 'StratoO3': np.float32(0.0), 'year': np.float32(0.07056126), 'month': np.float32(0.07492488), 'day': np.float32(0.018223098), 'dayofweek': np.float32(0.024259122)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([22.60120185,  1.60953184,  0.05630128,  0.421996  ,  0.70371621,\n",
      "       -2.09815042, 11.67340957,  1.40076074,  3.93063024, -0.30424482,\n",
      "        1.28789227,  1.57434223, -1.38504069, -0.65400137,  0.23881786,\n",
      "       -1.2576323 , -1.06099096, -2.86369461, -1.53092777,  1.71121286,\n",
      "       -1.0755135 , -1.54436684, -2.03649422, -0.35918851,  0.94110823,\n",
      "       -0.4164042 , -1.40886088, -4.9355656 ,  0.32746909,  0.31220468,\n",
      "        0.3371072 ,  1.1609177 , -0.4581361 , -9.84750384, -3.45410766,\n",
      "        0.63047059,  1.38713136])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([22.60120185,  1.60953184,  0.05630128,  0.421996  ,  0.70371621,\n",
      "       -2.09815042, 11.67340957,  1.40076074,  3.93063024, -0.30424482,\n",
      "        1.28789227,  1.57434223, -1.38504069, -0.65400137,  0.23881786,\n",
      "       -1.2576323 , -1.06099096, -2.86369461, -1.53092777,  1.71121286,\n",
      "       -1.0755135 , -1.54436684, -2.03649422, -0.35918851,  0.94110823,\n",
      "       -0.4164042 , -1.40886088, -4.9355656 ,  0.32746909,  0.31220468,\n",
      "        0.3371072 ,  1.1609177 , -0.4581361 , -9.84750384, -3.45410766,\n",
      "        0.63047059,  1.38713136]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 25.63\n",
      "  MAE: 20.22\n",
      "  R: 0.65\n",
      "Test Set:\n",
      "  RMSE: 30.17\n",
      "  MAE: 23.29\n",
      "  R: 0.29\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 25.71\n",
      "  MAE: 20.01\n",
      "  R: 0.64\n",
      "Test Set:\n",
      "  RMSE: 29.04\n",
      "  MAE: 22.21\n",
      "  R: 0.35\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 25.14\n",
      "  MAE: 20.17\n",
      "  R: 0.66\n",
      "Test Set:\n",
      "  RMSE: 25.27\n",
      "  MAE: 19.65\n",
      "  R: 0.50\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 24.15\n",
      "  MAE: 18.13\n",
      "  R: 0.69\n",
      "Test Set:\n",
      "  RMSE: 20.24\n",
      "  MAE: 14.45\n",
      "  R: 0.68\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 23.43\n",
      "  MAE: 17.80\n",
      "  R: 0.70\n",
      "Test Set:\n",
      "  RMSE: 22.47\n",
      "  MAE: 17.52\n",
      "  R: 0.61\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 23.36\n",
      "  MAE: 17.68\n",
      "  R: 0.71\n",
      "Test Set:\n",
      "  RMSE: 22.83\n",
      "  MAE: 17.81\n",
      "  R: 0.60\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 27.76\n",
      "  MAE: 21.40\n",
      "  R: 0.59\n",
      "Test Set:\n",
      "  RMSE: 30.74\n",
      "  MAE: 22.83\n",
      "  R: 0.27\n",
      "\n",
      "Processing delhi...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for delhi...\n",
      "\n",
      "Evaluating ridge for delhi...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for delhi...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for delhi...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for delhi...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for delhi...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for delhi...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(51.34949380944262), 'PM10': np.float64(41.18862506609617), 'NO': np.float64(5.264973981395489), 'NO2': np.float64(-4.855083765540358), 'NOx': np.float64(9.24749933509674), 'NH3': np.float64(-7.271051643881094), 'CO': np.float64(5.68203529778261), 'SO2': np.float64(-1.4923642839524707), 'O3': np.float64(0.46208172867869096), 'Benzene': np.float64(-7.703395489324661), 'Toluene': np.float64(8.185949429989245), 'tempmax': np.float64(-0.6275373559532816), 'tempmin': np.float64(34.59255597409115), 'temp': np.float64(-19.339920614172936), 'feelslikemax': np.float64(-9.90142905441469), 'feelslikemin': np.float64(-12.470912852213385), 'feelslike': np.float64(-24.95957679811408), 'dew': np.float64(31.639191391582337), 'humidity': np.float64(-47.93317443423777), 'precip': np.float64(0.022773843504135503), 'precipprob': np.float64(-0.9534823822069006), 'precipcover': np.float64(1.9811103413979962), 'windgust': np.float64(5.000348600852408), 'windspeed': np.float64(0.6005921392489176), 'winddir': np.float64(0.15713281989876932), 'sealevelpressure': np.float64(4.421447590956991), 'cloudcover': np.float64(-9.078705689844284), 'visibility': np.float64(-15.20541036031461), 'solarradiation': np.float64(-3.0591550623675805), 'solarenergy': np.float64(-4.627411243924511), 'uvindex': np.float64(-1.4833462055738684), 'moonphase': np.float64(0.32758763750605696), 'StratoO3': np.float64(1.1047481512505586), 'year': np.float64(-14.325670509585029), 'month': np.float64(-8.596089217903499), 'day': np.float64(0.17931245413128716), 'dayofweek': np.float64(2.275714791324216)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(51.20688973292946), 'PM10': np.float64(41.294229430800534), 'NO': np.float64(5.146103334841875), 'NO2': np.float64(-4.847935269687946), 'NOx': np.float64(9.201490453495868), 'NH3': np.float64(-7.199694680796956), 'CO': np.float64(5.669145573512049), 'SO2': np.float64(-1.4097311983086087), 'O3': np.float64(0.5753878632426771), 'Benzene': np.float64(-7.709334670880535), 'Toluene': np.float64(8.144564785853902), 'tempmax': np.float64(-1.8297166055123784), 'tempmin': np.float64(29.51775294285271), 'temp': np.float64(-11.32632629260871), 'feelslikemax': np.float64(-9.959961963526727), 'feelslikemin': np.float64(-10.21943877213011), 'feelslike': np.float64(-25.613962372825487), 'dew': np.float64(28.71422313316599), 'humidity': np.float64(-44.74866432329167), 'precip': np.float64(-0.004480066585144445), 'precipprob': np.float64(-0.9181758787131127), 'precipcover': np.float64(1.8857598163076004), 'windgust': np.float64(5.099592693896361), 'windspeed': np.float64(0.6394701173957577), 'winddir': np.float64(0.13218308458466715), 'sealevelpressure': np.float64(4.640621441283427), 'cloudcover': np.float64(-8.98461668569437), 'visibility': np.float64(-14.947497953062209), 'solarradiation': np.float64(-3.99581970530558), 'solarenergy': np.float64(-3.8952515558314116), 'uvindex': np.float64(-1.2516338373221871), 'moonphase': np.float64(0.3607878795857797), 'StratoO3': np.float64(1.0837963121445777), 'year': np.float64(-14.365213268440701), 'month': np.float64(-8.378944363335396), 'day': np.float64(0.13945680854845044), 'dayofweek': np.float64(2.2730633109919562)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(50.7423101471125), 'PM10': np.float64(40.63653566986256), 'NO': np.float64(0.0), 'NO2': np.float64(-0.0), 'NOx': np.float64(8.747780956441702), 'NH3': np.float64(-5.356208310644639), 'CO': np.float64(5.774423713455908), 'SO2': np.float64(0.0), 'O3': np.float64(0.2689349290037381), 'Benzene': np.float64(-0.29230074005728707), 'Toluene': np.float64(2.4332410737697465), 'tempmax': np.float64(0.0), 'tempmin': np.float64(0.0), 'temp': np.float64(0.0), 'feelslikemax': np.float64(-10.32733679226139), 'feelslikemin': np.float64(-0.0), 'feelslike': np.float64(-0.0), 'dew': np.float64(-0.0), 'humidity': np.float64(-18.769024598781122), 'precip': np.float64(0.0), 'precipprob': np.float64(-0.0), 'precipcover': np.float64(0.0), 'windgust': np.float64(3.606908251851775), 'windspeed': np.float64(0.7576860227087268), 'winddir': np.float64(0.0), 'sealevelpressure': np.float64(0.8108562122198861), 'cloudcover': np.float64(-3.2575681476719036), 'visibility': np.float64(-8.854543019548043), 'solarradiation': np.float64(-0.0), 'solarenergy': np.float64(-0.8081688252276252), 'uvindex': np.float64(-0.0), 'moonphase': np.float64(0.0), 'StratoO3': np.float64(0.13723456526465236), 'year': np.float64(-13.629711457550787), 'month': np.float64(-3.0340636756016357), 'day': np.float64(-0.0), 'dayofweek': np.float64(1.680477177533827)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.7337261401029019), 'PM10': np.float64(0.10842793322329063), 'NO': np.float64(0.0025545222623242917), 'NO2': np.float64(0.005427186630323312), 'NOx': np.float64(0.025737708989314035), 'NH3': np.float64(0.004407932132006238), 'CO': np.float64(0.019069674175704567), 'SO2': np.float64(0.0037746757854022583), 'O3': np.float64(0.00726647153475174), 'Benzene': np.float64(0.0035263186813245203), 'Toluene': np.float64(0.038444471464860026), 'tempmax': np.float64(0.0011349219998497534), 'tempmin': np.float64(0.0013305639600760496), 'temp': np.float64(0.0012857127021121584), 'feelslikemax': np.float64(0.0014576603881758228), 'feelslikemin': np.float64(0.0016013980880028103), 'feelslike': np.float64(0.0010921420177956304), 'dew': np.float64(0.004735089354792137), 'humidity': np.float64(0.002990836435624976), 'precip': np.float64(0.0003689826966358415), 'precipprob': np.float64(5.6906972313328864e-05), 'precipcover': np.float64(0.00012410992507052958), 'windgust': np.float64(0.002192235676888284), 'windspeed': np.float64(0.002089719188856099), 'winddir': np.float64(0.0026761336206728584), 'sealevelpressure': np.float64(0.002269309119766764), 'cloudcover': np.float64(0.001963899159041318), 'visibility': np.float64(0.0017964512113279037), 'solarradiation': np.float64(0.0016545272831596032), 'solarenergy': np.float64(0.001196793227529304), 'uvindex': np.float64(0.0003220521845138491), 'moonphase': np.float64(0.0018286859424900075), 'StratoO3': np.float64(0.003109007776112461), 'year': np.float64(0.006665027306894787), 'month': np.float64(0.0004496110949615979), 'day': np.float64(0.001783728423150528), 'dayofweek': np.float64(0.0014614592619821385)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.7097058145404178), 'PM10': np.float64(0.1252673015677763), 'NO': np.float64(0.003104306574252714), 'NO2': np.float64(0.003731493462376349), 'NOx': np.float64(0.016588798580250252), 'NH3': np.float64(0.004355116948983745), 'CO': np.float64(0.021465018111007192), 'SO2': np.float64(0.0036200408514070726), 'O3': np.float64(0.008167445839552616), 'Benzene': np.float64(0.003374439069294333), 'Toluene': np.float64(0.032239298381121405), 'tempmax': np.float64(0.0014907719915442296), 'tempmin': np.float64(0.001406294480219597), 'temp': np.float64(0.002432047601314276), 'feelslikemax': np.float64(0.0017574470684281803), 'feelslikemin': np.float64(0.001106734917329342), 'feelslike': np.float64(0.0008060563672163287), 'dew': np.float64(0.006368356508553465), 'humidity': np.float64(0.005813260059654532), 'precip': np.float64(0.0004911944440756608), 'precipprob': np.float64(8.65517992984497e-05), 'precipcover': np.float64(7.561862280172425e-05), 'windgust': np.float64(0.002834922943554544), 'windspeed': np.float64(0.0022309827728768717), 'winddir': np.float64(0.0029281854880975878), 'sealevelpressure': np.float64(0.003804570787309894), 'cloudcover': np.float64(0.0019063668498669557), 'visibility': np.float64(0.0007990960016871539), 'solarradiation': np.float64(0.0016945483945053066), 'solarenergy': np.float64(0.0014599580117092591), 'uvindex': np.float64(0.00040853094669506435), 'moonphase': np.float64(0.00174374320939369), 'StratoO3': np.float64(0.0023805606341879984), 'year': np.float64(0.022267455579972884), 'month': np.float64(0.0010680695884798179), 'day': np.float64(0.0005720561318633069), 'dayofweek': np.float64(0.00044754487292413166)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.41910893), 'PM10': np.float32(0.12830769), 'NO': np.float32(0.00348544), 'NO2': np.float32(0.0066897916), 'NOx': np.float32(0.023042701), 'NH3': np.float32(0.006805061), 'CO': np.float32(0.035168406), 'SO2': np.float32(0.005530081), 'O3': np.float32(0.012379786), 'Benzene': np.float32(0.0071034646), 'Toluene': np.float32(0.09135247), 'tempmax': np.float32(0.0050629703), 'tempmin': np.float32(0.008181615), 'temp': np.float32(0.005985805), 'feelslikemax': np.float32(0.0101708295), 'feelslikemin': np.float32(0.0029744091), 'feelslike': np.float32(0.004755607), 'dew': np.float32(0.012417261), 'humidity': np.float32(0.019976547), 'precip': np.float32(0.0022451354), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.003830562), 'windgust': np.float32(0.005724954), 'windspeed': np.float32(0.0050593694), 'winddir': np.float32(0.0047345227), 'sealevelpressure': np.float32(0.0056976974), 'cloudcover': np.float32(0.0054880353), 'visibility': np.float32(0.0069879917), 'solarradiation': np.float32(0.0068783504), 'solarenergy': np.float32(0.007166687), 'uvindex': np.float32(0.0033152676), 'moonphase': np.float32(0.0036657525), 'StratoO3': np.float32(0.0042746984), 'year': np.float32(0.115904), 'month': np.float32(0.0039789765), 'day': np.float32(0.00337209), 'dayofweek': np.float32(0.0031770102)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([ 55.90379381,  42.2434345 ,  -4.43728685,   1.15358782,\n",
      "        11.79717724,  -7.25760465,   7.45706155,   0.05988755,\n",
      "        -2.8443103 ,  -7.59461031,   6.75194687,   9.95898345,\n",
      "        19.3427929 , -11.36301187, -13.99303081,  -4.28031447,\n",
      "       -21.08505385,  19.93768214, -32.28489455,   0.22913595,\n",
      "         0.45938446,  -0.46895558,   4.05084542,   0.90041707,\n",
      "        -0.76910476,   2.87260632,  -6.92823658, -16.09317764,\n",
      "        -4.01540256,  -0.89598552,  -2.28521717,  -0.23115864,\n",
      "        -0.40507576, -13.01296406,  -7.32353845,  -0.77807841,\n",
      "         2.24710975])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([ 55.90379381,  42.2434345 ,  -4.43728685,   1.15358782,\n",
      "        11.79717724,  -7.25760465,   7.45706155,   0.05988755,\n",
      "        -2.8443103 ,  -7.59461031,   6.75194687,   9.95898345,\n",
      "        19.3427929 , -11.36301187, -13.99303081,  -4.28031447,\n",
      "       -21.08505385,  19.93768214, -32.28489455,   0.22913595,\n",
      "         0.45938446,  -0.46895558,   4.05084542,   0.90041707,\n",
      "        -0.76910476,   2.87260632,  -6.92823658, -16.09317764,\n",
      "        -4.01540256,  -0.89598552,  -2.28521717,  -0.23115864,\n",
      "        -0.40507576, -13.01296406,  -7.32353845,  -0.77807841,\n",
      "         2.24710975]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 37.30\n",
      "  MAE: 29.95\n",
      "  R: 0.90\n",
      "Test Set:\n",
      "  RMSE: 33.19\n",
      "  MAE: 25.33\n",
      "  R: 0.91\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 37.19\n",
      "  MAE: 29.86\n",
      "  R: 0.90\n",
      "Test Set:\n",
      "  RMSE: 33.09\n",
      "  MAE: 25.24\n",
      "  R: 0.92\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 32.19\n",
      "  MAE: 23.69\n",
      "  R: 0.92\n",
      "Test Set:\n",
      "  RMSE: 33.40\n",
      "  MAE: 23.83\n",
      "  R: 0.91\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 28.84\n",
      "  MAE: 21.54\n",
      "  R: 0.94\n",
      "Test Set:\n",
      "  RMSE: 29.84\n",
      "  MAE: 23.86\n",
      "  R: 0.93\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 29.58\n",
      "  MAE: 21.40\n",
      "  R: 0.94\n",
      "Test Set:\n",
      "  RMSE: 27.88\n",
      "  MAE: 21.27\n",
      "  R: 0.94\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 30.30\n",
      "  MAE: 21.68\n",
      "  R: 0.93\n",
      "Test Set:\n",
      "  RMSE: 27.99\n",
      "  MAE: 20.85\n",
      "  R: 0.94\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 34.19\n",
      "  MAE: 26.67\n",
      "  R: 0.91\n",
      "Test Set:\n",
      "  RMSE: 31.58\n",
      "  MAE: 23.69\n",
      "  R: 0.92\n",
      "\n",
      "Processing hyderabad...\n",
      "Evaluating ML models...\n",
      "\n",
      "Evaluating linear_regression for hyderabad...\n",
      "\n",
      "Evaluating ridge for hyderabad...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating lasso for hyderabad...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Evaluating random_forest for hyderabad...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Evaluating gradient_boosting for hyderabad...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating xgboost for hyderabad...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Evaluating svr for hyderabad...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Saving results...\n",
      "Generating visualizations...\n",
      "\n",
      "Debugging linear_regression:\n",
      "Feature importance structure: {'PM2.5': np.float64(39.17969195951329), 'PM10': np.float64(12.724180301816821), 'NO': np.float64(2.3495973338596277), 'NO2': np.float64(-5.7029259040246805), 'NOx': np.float64(-3.231626435968809), 'NH3': np.float64(4.298490916176191), 'CO': np.float64(14.73556958295244), 'SO2': np.float64(-4.374895847652137), 'O3': np.float64(7.519575455480197), 'Benzene': np.float64(-6.591982159417569), 'Toluene': np.float64(5.444088113025773), 'tempmax': np.float64(5.284843103938523), 'tempmin': np.float64(-17.748898085837304), 'temp': np.float64(-8.305654443228486), 'feelslikemax': np.float64(-4.462751154999087), 'feelslikemin': np.float64(15.246085616577666), 'feelslike': np.float64(-3.3584515268416375), 'dew': np.float64(11.276501613831272), 'humidity': np.float64(-7.897263489861939), 'precip': np.float64(-0.96925447749161), 'precipprob': np.float64(0.6152474740785931), 'precipcover': np.float64(-2.1697554709182216), 'windgust': np.float64(-2.081068114079231), 'windspeed': np.float64(-0.9198546825977856), 'winddir': np.float64(3.3119214759553306), 'sealevelpressure': np.float64(-6.48749537852535), 'cloudcover': np.float64(2.066983879749081), 'visibility': np.float64(-3.4928346559984047), 'solarradiation': np.float64(-32.18736750658936), 'solarenergy': np.float64(41.86688495548869), 'uvindex': np.float64(-5.972406494996017), 'moonphase': np.float64(0.1625929424373137), 'StratoO3': np.float64(-0.1414343327870413), 'year': np.float64(-9.040444195552686), 'month': np.float64(-2.8816091412627305), 'day': np.float64(-1.3108635623363587), 'dayofweek': np.float64(0.1090361707548631)}\n",
      "\n",
      "Debugging ridge:\n",
      "Feature importance structure: {'PM2.5': np.float64(38.90152876306824), 'PM10': np.float64(12.394301447779842), 'NO': np.float64(2.0633834536642333), 'NO2': np.float64(-5.235999856602204), 'NOx': np.float64(-2.9554483360856345), 'NH3': np.float64(4.15488586419116), 'CO': np.float64(14.55129068396122), 'SO2': np.float64(-4.124609120429513), 'O3': np.float64(7.455854821173043), 'Benzene': np.float64(-5.54279796447338), 'Toluene': np.float64(4.384316722862955), 'tempmax': np.float64(3.6593207707102624), 'tempmin': np.float64(-6.7414945100587955), 'temp': np.float64(-6.329515106973153), 'feelslikemax': np.float64(-3.883382228625378), 'feelslikemin': np.float64(3.972233769302472), 'feelslike': np.float64(-0.23247868122665086), 'dew': np.float64(6.155628724020132), 'humidity': np.float64(-2.7912128032802346), 'precip': np.float64(-1.0601145260425695), 'precipprob': np.float64(0.6326781388412133), 'precipcover': np.float64(-2.222331604230349), 'windgust': np.float64(-1.8110655716338666), 'windspeed': np.float64(-0.7917255487873321), 'winddir': np.float64(3.0696336027791924), 'sealevelpressure': np.float64(-5.731887367643284), 'cloudcover': np.float64(1.8087118902570969), 'visibility': np.float64(-3.4427127339776944), 'solarradiation': np.float64(3.399369598691447), 'solarenergy': np.float64(5.321032243737565), 'uvindex': np.float64(-5.169253704582865), 'moonphase': np.float64(0.18836040923037434), 'StratoO3': np.float64(-0.12268487281144216), 'year': np.float64(-9.406420474941694), 'month': np.float64(-3.1198132652926063), 'day': np.float64(-1.3016783639438367), 'dayofweek': np.float64(0.08581054149805147)}\n",
      "\n",
      "Debugging lasso:\n",
      "Feature importance structure: {'PM2.5': np.float64(39.230718462763505), 'PM10': np.float64(12.194826926127678), 'NO': np.float64(1.682209572364573), 'NO2': np.float64(-4.552568725029388), 'NOx': np.float64(-2.578929791512637), 'NH3': np.float64(3.8001502735328443), 'CO': np.float64(14.570979132479216), 'SO2': np.float64(-3.8093868388834986), 'O3': np.float64(7.261719183766523), 'Benzene': np.float64(-4.184920251379992), 'Toluene': np.float64(2.776110900977149), 'tempmax': np.float64(0.0), 'tempmin': np.float64(-3.092374777993228), 'temp': np.float64(-2.379463567797072), 'feelslikemax': np.float64(-1.6463109667580385), 'feelslikemin': np.float64(0.0), 'feelslike': np.float64(-0.0), 'dew': np.float64(3.0428433650558304), 'humidity': np.float64(-0.0), 'precip': np.float64(-0.8644815190147918), 'precipprob': np.float64(0.4235893769741491), 'precipcover': np.float64(-2.087127400316925), 'windgust': np.float64(-1.3380522831862809), 'windspeed': np.float64(-0.6490730868093951), 'winddir': np.float64(2.8902932323491295), 'sealevelpressure': np.float64(-5.088573062457625), 'cloudcover': np.float64(1.061315632230842), 'visibility': np.float64(-3.34178318539361), 'solarradiation': np.float64(0.0), 'solarenergy': np.float64(7.040865127130415), 'uvindex': np.float64(-3.8784769915932555), 'moonphase': np.float64(0.15781995705566904), 'StratoO3': np.float64(-0.0), 'year': np.float64(-9.677834651312633), 'month': np.float64(-3.124714545414266), 'day': np.float64(-1.2777907395481602), 'dayofweek': np.float64(0.03453897548908566)}\n",
      "\n",
      "Debugging random_forest:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.6675686196579843), 'PM10': np.float64(0.02013043598219816), 'NO': np.float64(0.006480898382987031), 'NO2': np.float64(0.016404811555737954), 'NOx': np.float64(0.00573815419069473), 'NH3': np.float64(0.006395628429132627), 'CO': np.float64(0.09155312678277477), 'SO2': np.float64(0.004533439579716001), 'O3': np.float64(0.027720279876513144), 'Benzene': np.float64(0.0037928407495757166), 'Toluene': np.float64(0.007947985991317724), 'tempmax': np.float64(0.005036993621592886), 'tempmin': np.float64(0.0023104064413573544), 'temp': np.float64(0.007645197768598999), 'feelslikemax': np.float64(0.005174785522277511), 'feelslikemin': np.float64(0.0031713783609363727), 'feelslike': np.float64(0.008099305243656095), 'dew': np.float64(0.0050008038886755046), 'humidity': np.float64(0.006124759903927235), 'precip': np.float64(0.0040917379899531045), 'precipprob': np.float64(0.0004553377527750442), 'precipcover': np.float64(0.0034200268077503857), 'windgust': np.float64(0.013168777470230366), 'windspeed': np.float64(0.004849921395929057), 'winddir': np.float64(0.008520922887843226), 'sealevelpressure': np.float64(0.014132659821999093), 'cloudcover': np.float64(0.006731549812696712), 'visibility': np.float64(0.0035462998157495614), 'solarradiation': np.float64(0.004212330067541311), 'solarenergy': np.float64(0.0027676244698386187), 'uvindex': np.float64(0.0024537577423310256), 'moonphase': np.float64(0.006055393987424709), 'StratoO3': np.float64(0.008400416557619576), 'year': np.float64(0.004463646622245936), 'month': np.float64(0.0013704033271487283), 'day': np.float64(0.006515540804272879), 'dayofweek': np.float64(0.004013800736996532)}\n",
      "\n",
      "Debugging gradient_boosting:\n",
      "Feature importance structure: {'PM2.5': np.float64(0.704414269979022), 'PM10': np.float64(0.019868451331948245), 'NO': np.float64(0.0031307058440963047), 'NO2': np.float64(0.008379072186954327), 'NOx': np.float64(0.0023349068906987117), 'NH3': np.float64(0.0040371008596859085), 'CO': np.float64(0.09300058513874532), 'SO2': np.float64(0.004320847251059389), 'O3': np.float64(0.04632229409171671), 'Benzene': np.float64(0.008069191661284364), 'Toluene': np.float64(0.0050707772475585364), 'tempmax': np.float64(0.0005566451279882217), 'tempmin': np.float64(0.000614430679813513), 'temp': np.float64(0.0011631256703412505), 'feelslikemax': np.float64(0.001371487841890044), 'feelslikemin': np.float64(0.001309734434265201), 'feelslike': np.float64(0.005380554580462934), 'dew': np.float64(0.00845439313150706), 'humidity': np.float64(0.002287930217027693), 'precip': np.float64(0.0016094875525228432), 'precipprob': np.float64(7.69085952069616e-06), 'precipcover': np.float64(0.0002472445339153454), 'windgust': np.float64(0.015240942550073322), 'windspeed': np.float64(0.003831369887223155), 'winddir': np.float64(0.008868118020967406), 'sealevelpressure': np.float64(0.00436976998856409), 'cloudcover': np.float64(0.009791045143683034), 'visibility': np.float64(0.0025089975522334944), 'solarradiation': np.float64(0.003372994798128979), 'solarenergy': np.float64(0.0004974555188642984), 'uvindex': np.float64(0.0), 'moonphase': np.float64(0.0028207946043636613), 'StratoO3': np.float64(0.003658456653320404), 'year': np.float64(0.013422446459681853), 'month': np.float64(0.004054418799312264), 'day': np.float64(0.0005644720325275561), 'dayofweek': np.float64(0.005047790879031952)}\n",
      "\n",
      "Debugging xgboost:\n",
      "Feature importance structure: {'PM2.5': np.float32(0.31335124), 'PM10': np.float32(0.029820526), 'NO': np.float32(0.006897491), 'NO2': np.float32(0.0147953415), 'NOx': np.float32(0.0150353), 'NH3': np.float32(0.026713453), 'CO': np.float32(0.086608246), 'SO2': np.float32(0.00982153), 'O3': np.float32(0.023238435), 'Benzene': np.float32(0.00998035), 'Toluene': np.float32(0.014209648), 'tempmax': np.float32(0.008159979), 'tempmin': np.float32(0.013030665), 'temp': np.float32(0.080830306), 'feelslikemax': np.float32(0.004197526), 'feelslikemin': np.float32(0.0), 'feelslike': np.float32(0.0006216143), 'dew': np.float32(0.095760465), 'humidity': np.float32(0.02168406), 'precip': np.float32(0.028577544), 'precipprob': np.float32(0.0), 'precipcover': np.float32(0.0), 'windgust': np.float32(0.016814116), 'windspeed': np.float32(0.007494188), 'winddir': np.float32(0.009813723), 'sealevelpressure': np.float32(0.031036979), 'cloudcover': np.float32(0.018704273), 'visibility': np.float32(0.0069159637), 'solarradiation': np.float32(0.007721123), 'solarenergy': np.float32(0.0), 'uvindex': np.float32(0.0), 'moonphase': np.float32(0.0055023585), 'StratoO3': np.float32(0.012642782), 'year': np.float32(0.051086396), 'month': np.float32(0.017326083), 'day': np.float32(0.0032809102), 'dayofweek': np.float32(0.0083274925)}\n",
      "\n",
      "Debugging svr:\n",
      "Feature importance structure: {'PM2.5': array([ 34.31728246,  14.17761586,   3.67904066,  -3.70413061,\n",
      "        -4.40184778,   2.58516921,  14.51637316,  -2.5433212 ,\n",
      "         7.15683904,  -2.16127469,   2.44309709,   5.73107548,\n",
      "        -6.84638822, -11.18739714,  -4.96707273,   5.74081524,\n",
      "         9.11834134,   0.28125014,  -0.0436251 ,   0.39493506,\n",
      "         0.62753248,   0.48933253,   0.14803813,  -0.50790883,\n",
      "         2.4009893 ,  -3.08430283,   1.29522731,  -2.27276047,\n",
      "         2.32952826,   2.97417116,  -3.58628375,   0.35143826,\n",
      "         0.18179901,  -6.70669031,  -2.46245702,  -1.10076852,\n",
      "        -0.31547849])}\n",
      "Error converting values: only length-1 arrays can be converted to Python scalars\n",
      "Original values: (array([ 34.31728246,  14.17761586,   3.67904066,  -3.70413061,\n",
      "        -4.40184778,   2.58516921,  14.51637316,  -2.5433212 ,\n",
      "         7.15683904,  -2.16127469,   2.44309709,   5.73107548,\n",
      "        -6.84638822, -11.18739714,  -4.96707273,   5.74081524,\n",
      "         9.11834134,   0.28125014,  -0.0436251 ,   0.39493506,\n",
      "         0.62753248,   0.48933253,   0.14803813,  -0.50790883,\n",
      "         2.4009893 ,  -3.08430283,   1.29522731,  -2.27276047,\n",
      "         2.32952826,   2.97417116,  -3.58628375,   0.35143826,\n",
      "         0.18179901,  -6.70669031,  -2.46245702,  -1.10076852,\n",
      "        -0.31547849]),)\n",
      "\n",
      "Model Performance Summary:\n",
      "\n",
      "Linear Regression:\n",
      "Val Set:\n",
      "  RMSE: 16.86\n",
      "  MAE: 14.05\n",
      "  R: 0.60\n",
      "Test Set:\n",
      "  RMSE: 19.08\n",
      "  MAE: 15.82\n",
      "  R: 0.71\n",
      "\n",
      "Ridge:\n",
      "Val Set:\n",
      "  RMSE: 17.09\n",
      "  MAE: 14.48\n",
      "  R: 0.59\n",
      "Test Set:\n",
      "  RMSE: 18.98\n",
      "  MAE: 15.61\n",
      "  R: 0.72\n",
      "\n",
      "Lasso:\n",
      "Val Set:\n",
      "  RMSE: 17.32\n",
      "  MAE: 14.80\n",
      "  R: 0.57\n",
      "Test Set:\n",
      "  RMSE: 18.59\n",
      "  MAE: 15.04\n",
      "  R: 0.73\n",
      "\n",
      "Random Forest:\n",
      "Val Set:\n",
      "  RMSE: 11.65\n",
      "  MAE: 9.26\n",
      "  R: 0.81\n",
      "Test Set:\n",
      "  RMSE: 16.37\n",
      "  MAE: 13.53\n",
      "  R: 0.79\n",
      "\n",
      "Gradient Boosting:\n",
      "Val Set:\n",
      "  RMSE: 9.96\n",
      "  MAE: 7.88\n",
      "  R: 0.86\n",
      "Test Set:\n",
      "  RMSE: 14.01\n",
      "  MAE: 11.77\n",
      "  R: 0.84\n",
      "\n",
      "Xgboost:\n",
      "Val Set:\n",
      "  RMSE: 9.79\n",
      "  MAE: 7.86\n",
      "  R: 0.86\n",
      "Test Set:\n",
      "  RMSE: 14.70\n",
      "  MAE: 12.51\n",
      "  R: 0.83\n",
      "\n",
      "Svr:\n",
      "Val Set:\n",
      "  RMSE: 14.34\n",
      "  MAE: 11.95\n",
      "  R: 0.71\n",
      "Test Set:\n",
      "  RMSE: 16.01\n",
      "  MAE: 12.46\n",
      "  R: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Initialize results manager\n",
    "results_manager = ModelResultsManager()\n",
    "\n",
    "# Run ML analysis\n",
    "run_ml_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
